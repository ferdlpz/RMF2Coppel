{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRec recommender engine:\n",
    "## Prototyping of a recommender system in Python using TensorRec including input data manipulation, algorithm design, and usage for prediction.\n",
    "\n",
    "#### TensorRec is a Python package for building recommender systems. A TensorRec recommender system consumes three pieces of input data: user features, item features, and interactions. Based on the user/item features, the system will predict which items to recommend. The interactions are used when fitting the model: predictions are compared to the interactions and a loss/penalty is calculated, which the system learns to decrease. As we prototype our system, we tackle three major situations: how we handle interactions, how we handle features, and how we structure the recommender itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*YotDpHjvGL8xK91ZggthbA.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/getting-started-with-recommender-systems-and-tensorrec-8f50a9943eef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw ratings load :Each row represents a single rating: one user and one item. We’ll be using these ratings(frequency of purchase of each item) as our interactions between the user and the product."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import six\n",
    "print(six.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!pip install --upgrade six==1.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import time\n",
    "t0 = time.time()\n",
    "limite = 189857*4 # 18,985,770  # corre en mi local %0.1 del total de la muestra\n",
    "\n",
    "# functions\n",
    "def get_data_BQ(sql):\n",
    "    client = bigquery.Client()\n",
    "    df = client.query(sql).to_dataframe()\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\n",
      "FROM `rmf2gcp.RawData.Workflow_aggregado`\n",
      "WHERE id_table_dem <=  759428 ORDER BY USERID\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10002, 210065, 1],\n",
       " [10002, 219060, 1],\n",
       " [10002, 229008, 1],\n",
       " [10002, 210070, 1],\n",
       " [10002, 869007, 4],\n",
       " [10002, 665040, 1],\n",
       " [10002, 248001, 1]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql =  '''SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\n",
    "FROM `rmf2gcp.RawData.Workflow_aggregado`\n",
    "WHERE id_table_dem <=  ''' + str(limite) + ''' ORDER BY USERID'''\n",
    "\n",
    "print(sql)\n",
    "raw_ratings = get_data_BQ(sql)\n",
    "raw_ratings = raw_ratings.values.tolist() # pues vamos a seguir su mala practica de hacer una lista de listas \n",
    "raw_ratings[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the input to map Item and User IDs to new internal IDs\n",
    "### The new internal IDs will be created by the defaultdict on insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759428\n",
      "2328\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "idcte_to_internal_user_ids = collections.defaultdict(lambda: len(idcte_to_internal_user_ids))\n",
    "idfam1_to_internal_item_ids = collections.defaultdict(lambda: len(idfam1_to_internal_item_ids))\n",
    "for row in raw_ratings:\n",
    "    row[0] = idcte_to_internal_user_ids[int(row[0])]\n",
    "    row[1] = idfam1_to_internal_item_ids[int(row[1])]\n",
    "    row[2] = float(row[2])    # esta operacion esta de más \n",
    "n_users = len(idcte_to_internal_user_ids)\n",
    "n_items = len(idfam1_to_internal_item_ids)\n",
    "print(n_users)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(210065, 0), (219060, 1), (229008, 2), (210070, 3), (869007, 4), (665040, 5), (248001, 6)]\n",
      "[(10002, 0), (10006, 1), (10011, 2), (10036, 3), (10039, 4), (10043, 5), (10047, 6)]\n"
     ]
    }
   ],
   "source": [
    "print( [ (key, value) for key, value  in idfam1_to_internal_item_ids.items() ][0:7])\n",
    "print( [ (key, value) for key, value  in idcte_to_internal_user_ids.items() ][0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import numpy \n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, we’ll break the ratings in to a training and test set by shuffling and splitting the ratings. Our prototypes will be trained on the training set, and we’ll evaluate their success using the test set. Splitting the train/test sets at random like this is crude, and there are more rigorous techniques for model evaluation, but it is quick and clear for the purposes of this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the ratings and split them in to train/test sets 80%/20%\n",
    "random.shuffle(raw_ratings)  # Shuffles the list in-place\n",
    "cutoff = int(.8 * len(raw_ratings))\n",
    "train_ratings = raw_ratings[:cutoff]\n",
    "test_ratings = raw_ratings[cutoff:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we reorganize these ratings in to a Scipy sparse matrix. In this matrix, every row represents a user and every column is an item. The [i, j]th value in this matrix is User i’s interaction with Item j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This method converts a list of (user, item, rating) to a sparse matrix\n",
    "def interactions_list_to_sparse_matrix(interactions):\n",
    "    users_column, items_column, ratings_column, = zip(*interactions)\n",
    "    return sparse.coo_matrix((ratings_column, (users_column, items_column)),\n",
    "                             shape=(n_users, n_items))\n",
    "\n",
    "\n",
    "# Create sparse matrices of interaction data\n",
    "sparse_train_ratings = interactions_list_to_sparse_matrix(raw_ratings)\n",
    "sparse_test_ratings = interactions_list_to_sparse_matrix(test_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<759428x2328 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14628541 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_train_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRec library runs on TensorFlow so we install a compatible version of TensorFlow \n",
    "### Both TensorFlow and TensorRec can be installed using !pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759428\n"
     ]
    }
   ],
   "source": [
    "#!pip install \"tensorflow==1.13.1\"\n",
    "print(n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.3-dlenv_tfe\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorrec --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter Prototype\n",
    "### A collaborative filter is an algorithm that learns which users have similar tastes and recommends items to a user based on what similar users have liked. A common way to do this is through matrix factorization. In matrix factorization, we have to learn two matrices (user representations and item representations) that, when multiplied together, approximate the interactions:\n",
    "#### TensorRec will perform matrix factorization by default if it is given only identity matrices as user/item features. These identity matrices are often called “indicator features.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training collaborative filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Construct indicator features for users and items\n",
    "user_indicator_features = sparse.identity(n_users)\n",
    "item_indicator_features = sparse.identity(n_items)\n",
    "\n",
    "# Build a matrix factorization collaborative filter model\n",
    "cf_model = tensorrec.TensorRec(n_components=5)\n",
    "\n",
    "# Fit the collaborative filter model\n",
    "print(\"Training collaborative filter\")\n",
    "cf_model.fit(interactions=sparse_train_ratings,\n",
    "             user_features=user_indicator_features,\n",
    "             item_features=item_indicator_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Graphs\n",
    "### One way we can configure our TensorRec system is by changing the loss graph. The loss graph takes in predictions and interactions and calculates a penalty (loss) that the system will try to decrease as it learns.\n",
    "#### WMRB, which stands for “weighted margin-rank batch,” works by taking a random sample of items the user hasn’t interacted with and comparing their predictions to items the user likes. Over time, this pushes items a user likes to the top of the rankings. We can try using different loss graphs like WARP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Let's try a new loss function: WMRB \n",
    "'''\n",
    "print(\"Training collaborative filter with WMRB loss\")\n",
    "ranking_cf_model = tensorrec.TensorRec(n_components=5,\n",
    "                                       loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "ranking_cf_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                     user_features=user_indicator_features,\n",
    "                     item_features=item_indicator_features,\n",
    "                     n_sampled_items=int(n_items *1))\n",
    "\n",
    "# Check the results of the WMRB MF CF model\n",
    "print(\"WMRB matrix factorization collaborative filter:\")\n",
    "predicted_ranks = ranking_cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                                item_features=item_indicator_features)\n",
    "                                                '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Metadata Features\n",
    "## To continue experimenting, we should try to make use of other data available to us. We will try using User Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT USERID, FEATURES, STATE\n",
      "FROM `rmf2gcp.RawData.demographics_features` \n",
      "WHERE id_table_dem <= 759428\n"
     ]
    }
   ],
   "source": [
    "# To improve the recommendations, lets read in the user demographic data\n",
    "sql = \"\"\"\n",
    "SELECT USERID, FEATURES, STATE\n",
    "FROM `rmf2gcp.RawData.demographics_features` \n",
    "WHERE id_table_dem <= \"\"\" + str(limite)\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     USERID FEATURES                      STATE\n",
      "0     10006   81,C,M  SINALOA                  \n",
      "1     10050   75,C,M  SINALOA                  \n",
      "2     10054   76,C,F  SINALOA                  \n",
      "3     10059   87,C,M  SINALOA                  \n",
      "4     10061   76,C,F  SINALOA                  \n",
      "..      ...      ...                        ...\n",
      "795   19683   76,C,F  SINALOA                  \n",
      "796   19714   65,S,F  SINALOA                  \n",
      "797   19725   68,S,F  SINALOA                  \n",
      "798   19741   74,S,F  SINALOA                  \n",
      "799   19750   75,C,M  SINALOA                  \n",
      "\n",
      "[800 rows x 3 columns]\n",
      "USERID       int64\n",
      "FEATURES    object\n",
      "STATE       object\n",
      "dtype: object\n",
      "Index(['USERID', 'FEATURES', 'STATE'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['USERID', 'FEATURES', 'STATE']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_user_metadata = get_data_BQ(sql)\n",
    "print(raw_user_metadata.head(800))\n",
    "print(raw_user_metadata.dtypes)\n",
    "print(raw_user_metadata.columns)\n",
    "raw_user_metadata_header = ['USERID', 'FEATURES', 'STATE']\n",
    "raw_user_metadata_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10006, '81,C,M', 'SINALOA                  '],\n",
       " [10050, '75,C,M', 'SINALOA                  '],\n",
       " [10054, '76,C,F', 'SINALOA                  '],\n",
       " [10059, '87,C,M', 'SINALOA                  '],\n",
       " [10061, '76,C,F', 'SINALOA                  '],\n",
       " [10066, '77,C,F', 'SINALOA                  '],\n",
       " [10097, '75,C,M', 'SINALOA                  ']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_user_metadata = raw_user_metadata.values.tolist()\n",
    "raw_user_metadata[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we’ll want to read this data, map the movies to our internal IDs, and keep track of the features for each user. Then we’ll binarize the feature  labels using Scikit’s MultiLabelBinarizer. The binarized output will be our features for our new recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw metadata example:\n",
      "['USERID', 'FEATURES', 'STATE']\n",
      "[2328, ['81', 'C', 'M'], 'SINALOA                  ']\n"
     ]
    }
   ],
   "source": [
    "# Map the features IDs to our internal IDs and keep track of the gender and age\n",
    "temp_string = ''\n",
    "temp_list = []\n",
    "count = 1\n",
    "user_id_by_internal_id = {}\n",
    "user_features_by_internal_id = {}\n",
    "for row in raw_user_metadata:\n",
    "    temp_string = ''\n",
    "    temp_list = []\n",
    "    \n",
    "\n",
    "    temp_string = str(row[0])\n",
    "    temp_list = row[1].split(',')\n",
    "    #print(count)\n",
    "    #print(temp_string)\n",
    "    #print(temp_list)\n",
    "    row[0] = idfam1_to_internal_item_ids[int(temp_string)]  # Map to IDs\n",
    "    row[1] = temp_list  # Split up\n",
    "    user_id_by_internal_id[temp_string] = temp_string\n",
    "    user_features_by_internal_id[int(temp_string)] = row[1]\n",
    "    count+=1\n",
    "# Look at an example user metadata row\n",
    "print(\"Raw metadata example:\\n{}\\n{}\".format(raw_user_metadata_header, \n",
    "                                             raw_user_metadata[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10006, ['81', 'C', 'M']),\n",
       " (10050, ['75', 'C', 'M']),\n",
       " (10054, ['76', 'C', 'F']),\n",
       " (10059, ['87', 'C', 'M']),\n",
       " (10061, ['76', 'C', 'F']),\n",
       " (10066, ['77', 'C', 'F']),\n",
       " (10097, ['75', 'C', 'M'])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (key, value) for key,value in user_features_by_internal_id.items() ][0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a list of features where the index is the internal user ID and the value is a list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = [user_features_by_internal_id[internal_id]\n",
    "                for internal_id in user_features_by_internal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['81', 'C', 'M'],\n",
       " ['75', 'C', 'M'],\n",
       " ['76', 'C', 'F'],\n",
       " ['87', 'C', 'M'],\n",
       " ['76', 'C', 'F'],\n",
       " ['77', 'C', 'F'],\n",
       " ['75', 'C', 'M']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "29 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the features into binarized labels using scikit's MultiLabelBinarizer\n",
    "user_features = MultiLabelBinarizer().fit_transform(user_feat)\n",
    "n_features = user_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 #perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coerce the user features to a sparse matrix, which TensorRec expects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<759428x96 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2278284 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_mat = sparse.coo_matrix(user_features)\n",
    "user_features_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s not as good as the ranking collaborative filter but it’s significantly more effective if we add it to the base collaborative filter.\n",
    "#### There is a major weakness to this system: user feature alone are not very descriptive and are not enough information to make an informed recommendation. If we had more descriptive metadata and item metadata (views, clicks, basket information etc.) we may have more success with this content-based recommender system.\n",
    "#### On the other hand, there is a major strength to this system: by relying on only metadata features, and not using indicator features, we can recommend products which were not present when training the model. Similarly, if we have valuable user metadata we can avoid using user indicator features and make predictions for users who’ve never interacted with a product before. This is called “cold-start” recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid recommender: \n",
    "## Hybrid recommender systems combine two or more recommendation strategies in different ways to benefit from their complementary advantages.\n",
    "### Let’s combine these two: we’ll use indicator features to get the strengths of a collaborative filter, and we’ll also use the content features to take advantage of the metadata. This combination of collaborative filtering and content-based recommendation is the hybrid model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do this by stacking the two sets of features together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<759428x759524 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3037712 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try concatenating the user features on to the indicator features for a hybrid recommender system\n",
    "full_user_features = sparse.hstack([user_indicator_features, user_features_mat])\n",
    "full_user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:n_sampled_items was specified, but the loss graph is not sample-based\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hybrid recommender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Training hybrid recommender\")\n",
    "hybrid_model = tensorrec.TensorRec(\n",
    "    n_components=5\n",
    ")\n",
    "hybrid_model.fit(interactions=sparse_train_ratings,\n",
    "                 user_features=full_user_features,\n",
    "                 item_features=item_indicator_features,\n",
    "                 n_sampled_items=int(n_items * .01))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This performs the best even though we are using trivial features from users. If we have more metadata, we can expect larger impact of the Hybrid recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid recommender:\n",
      "Performance metrics: Train: 0.0294 Test: 0.0322\n"
     ]
    }
   ],
   "source": [
    "print(\"Hybrid recommender:\")\n",
    "predicted_ranks = hybrid_model.predict_rank(user_features=full_user_features,\n",
    "                                            item_features=item_indicator_features)\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Performance metrics: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the model: first prototype\n",
    "#### To do this, we’ll look at a metric called “recall at K.” Recall@K says, for the average user, what percentage of their test items made it in to the top K in the predicted rankings.\n",
    "#### Recall@K is a nice metric for many recommender systems because it emulates the behavior of a recommendation product. Before calculating the recall, we’ll want to decide which interactions should count as a “purchased item.” In this case, choose to use all ratings of at least 1.0 as “liked products” and ignore the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factorization collaborative filter:\n",
      "Performance metrics: Train: 0.0043 Test: 0.0043\n"
     ]
    }
   ],
   "source": [
    "# Create sets of train/test interactions that are only frequency > 1 since these represent the products that have been purchased \n",
    "sparse_train_ratings_1plus = sparse_train_ratings.multiply(sparse_train_ratings >= 1)\n",
    "sparse_test_ratings_1plus = sparse_test_ratings.multiply(sparse_test_ratings >= 1)\n",
    "\n",
    "\n",
    "# This method consumes item ranks for each user and prints out train/test metrics\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Performance metrics: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "\n",
    "# Check the results of the MF CF model\n",
    "print(\"Matrix factorization collaborative filter:\")\n",
    "predicted_ranks = cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                        item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "38 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "39 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43 #perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Recommendation\n",
    "### Now that we have metadata about our user, one thing we can try is to recommend based solely on the user metadata.\n",
    "### To do this, we will configure a TensorRec model to use a pass-through representation graph for item features. For us, this means that the user representations will be the same as the user features that are passed in (just the user information like gender, age etc.) and the item representations will reflect how much the item suits that particular set of user features.\n",
    "#### Ideal case is when we would have item metadata as well: because that would have a greater impact on making the recommendation better- also help solving the cold start problem. There is a major weakness to this system: these features alone are not very descriptive and are not enough information to make an informed recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training content-based recommender\n"
     ]
    }
   ],
   "source": [
    "# Fit a content-based model using the user features\n",
    "print(\"Training content-based recommender\")\n",
    "content_model = tensorrec.TensorRec(\n",
    "    n_components=n_features,\n",
    "   user_repr_graph=tensorrec.representation_graphs.FeaturePassThroughRepresentationGraph()\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:n_sampled_items was specified, but the loss graph is not sample-based\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "content_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                  user_features=user_features_mat,\n",
    "                  item_features=item_indicator_features,\n",
    "                  n_sampled_items=int(n_items * .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-based recommender:\n",
      "Performance metrics: Train: 0.0254 Test: 0.0274\n"
     ]
    }
   ],
   "source": [
    "# Check the results of the content-based model\n",
    "print(\"Content-based recommender:\")\n",
    "predicted_ranks = content_model.predict_rank(user_features=user_features_mat,\n",
    "                                             item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48 # perdido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49 # perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s not as good as the ranking collaborative filter but it’s significantly more effective if we add it to the base collaborative filter.\n",
    "#### There is a major weakness to this system: user feature alone are not very descriptive and are not enough information to make an informed recommendation. If we had more descriptive metadata and item metadata (views, clicks, basket information etc.) we may have more success with this content-based recommender system.\n",
    "#### On the other hand, there is a major strength to this system: by relying on only metadata features, and not using indicator features, we can recommend products which were not present when training the model. Similarly, if we have valuable user metadata we can avoid using user indicator features and make predictions for users who’ve never interacted with a product before. This is called “cold-start” recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making recommendations\n",
    "### We do this by passing the user’s feature vector and all the item features to predict_rank() and examining the resulting rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_internal 375 , para usuario 12198\n",
      "User x: Item recommendations:\n",
      "[204006, 308006, 314020, 327077, 330011, 338006, 510020, 510035, 603432, 630010]\n",
      "[110030, 296016, 316068, 326113, 330002, 408007, 495003, 501027, 750014, 802020]\n"
     ]
    }
   ],
   "source": [
    "# Pull user features out of the user features matrix and predict for just that user\n",
    "id_coppel =  12198# el cliente con mas compras en la muestra del %.01 # 18988462 # el cliente con mas compras coppel\n",
    "id_internal = idcte_to_internal_user_ids[id_coppel]\n",
    "print('id_internal {} , para usuario {}'.format(id_internal, id_coppel))\n",
    "u_features = sparse.csr_matrix(user_indicator_features)[id_internal  ] # el menos uno es importante \n",
    "u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "\n",
    "# Get internal IDs of User 432's top 10 recommendations\n",
    "# These are sorted by item ID, not by rank\n",
    "# This may contain items with which User 432 has already interacted\n",
    "k = 10\n",
    "u_top_ten_recs = numpy.where(u_rankings <= k)[0]\n",
    "u_top_ten_recs_foo = u_rankings[0:k]# yo creo que los rankings son mas bien\n",
    "print(\"User x: Item recommendations:\")\n",
    "u_top_ten_recs = [ key for key,value in idfam1_to_internal_item_ids.items() if value in u_top_ten_recs ]\n",
    "u_top_ten_recs.sort()\n",
    "u_top_ten_recs_foo = [ key for key, value in idfam1_to_internal_item_ids.items() if value in u_top_ten_recs_foo]\n",
    "u_top_ten_recs_foo.sort()\n",
    "print(u_top_ten_recs)\n",
    "print(u_top_ten_recs_foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The value of the range over which the recommender should iterate has to be the same as the # of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User0: Item recommendations:\n",
      "[ 109  163  454  486  745 1029 1173 1792 2177 2210]\n",
      "User10000: Item recommendations:\n",
      "[  43  439  616  773 1093 1599 1624 1699 1711 1855]\n",
      "User20000: Item recommendations:\n",
      "[ 132  353  804  828 1056 1150 1223 1316 1395 1741]\n",
      "User30000: Item recommendations:\n",
      "[ 726  729  940 1189 1322 1486 1491 1575 1893 1906]\n",
      "User40000: Item recommendations:\n",
      "[  90  203  420  461  619 1433 1684 1717 2031 2201]\n",
      "User50000: Item recommendations:\n",
      "[ 123  239  268 1235 1481 1607 2051 2060 2111 2244]\n",
      "User60000: Item recommendations:\n",
      "[  69  189  216 1122 1125 1335 1522 1631 1670 2316]\n",
      "User70000: Item recommendations:\n",
      "[ 442  624  786 1208 1273 1306 1397 1695 2192 2252]\n",
      "User80000: Item recommendations:\n",
      "[ 461  545  567  884 1498 1781 1877 1969 2108 2223]\n",
      "User90000: Item recommendations:\n",
      "[ 153  315  464  566 1160 1700 1804 1830 2084 2182]\n",
      "User100000: Item recommendations:\n",
      "[ 158  241  415  552 1212 1301 1676 1911 2067 2249]\n",
      "User110000: Item recommendations:\n",
      "[  91  118  281 1285 1379 1414 1859 2003 2275 2296]\n",
      "User120000: Item recommendations:\n",
      "[ 113  535  634  751 1157 1442 1698 2021 2057 2182]\n",
      "User130000: Item recommendations:\n",
      "[ 624  659  845 1208 1273 1328 1344 1695 2155 2261]\n",
      "User140000: Item recommendations:\n",
      "[  80  147  564  888  976 1126 1674 1882 2082 2312]\n",
      "User150000: Item recommendations:\n",
      "[ 135  628  806 1090 1329 1398 1462 1835 2133 2267]\n",
      "User160000: Item recommendations:\n",
      "[ 262  304  423  864  869 1452 1574 1817 2103 2196]\n",
      "User170000: Item recommendations:\n",
      "[ 101  300  585  802  806 1230 1244 1385 1436 1691]\n",
      "User180000: Item recommendations:\n",
      "[  43  439  773 1093 1521 1624 1711 1855 2171 2183]\n",
      "User190000: Item recommendations:\n",
      "[ 261  363  730 1054 1478 2011 2039 2052 2114 2326]\n",
      "User200000: Item recommendations:\n",
      "[ 139  306  590  839 1685 1744 1961 1982 2071 2174]\n",
      "User210000: Item recommendations:\n",
      "[  57   73  292  572  584  640  702 1181 1521 2183]\n",
      "User220000: Item recommendations:\n",
      "[  28   74  229  727 1083 1124 1255 1257 1552 1748]\n",
      "User230000: Item recommendations:\n",
      "[ 308  767 1141 1288 1374 1698 1718 1985 2021 2096]\n",
      "User240000: Item recommendations:\n",
      "[ 115  347  635  742  829  853  962 1183 1590 1787]\n",
      "User250000: Item recommendations:\n",
      "[  30   86  556  987 1080 1151 1447 1474 1707 1810]\n",
      "User260000: Item recommendations:\n",
      "[ 270  565  887 1587 1603 1671 1798 1859 1986 2301]\n",
      "User270000: Item recommendations:\n",
      "[ 599  644  893  941 1389 1735 1776 1788 2170 2224]\n",
      "User280000: Item recommendations:\n",
      "[  33  135 1011 1028 1083 1112 1407 1914 2264 2267]\n",
      "User290000: Item recommendations:\n",
      "[ 599  893 1298 1389 1671 1735 1776 1798 2022 2224]\n",
      "User300000: Item recommendations:\n",
      "[ 791  839 1018 1170 1390 1551 1685 1694 1744 2042]\n",
      "User310000: Item recommendations:\n",
      "[ 319  525  697  963 1081 1437 1484 1727 1864 2077]\n",
      "User320000: Item recommendations:\n",
      "[  65  534  786 1024 1402 1890 2076 2115 2192 2279]\n",
      "User330000: Item recommendations:\n",
      "[ 171  428  867  895 1206 1430 1625 1848 1859 2262]\n",
      "User340000: Item recommendations:\n",
      "[ 153  207  464  598  737  763 1032 1318 1830 1866]\n",
      "User350000: Item recommendations:\n",
      "[ 115  347  829  853  962 1183 1590 1627 1684 1787]\n",
      "User360000: Item recommendations:\n",
      "[ 135  270  293  700  792  905 1233 1462 1603 1835]\n",
      "User370000: Item recommendations:\n",
      "[ 238  384  713  909 1007 1252 1776 1788 1839 2135]\n",
      "User380000: Item recommendations:\n",
      "[  12  644  852  941  984 1197 1285 1333 1812 2208]\n",
      "User390000: Item recommendations:\n",
      "[  43  252  439  773  973 1711 1855 1966 2159 2171]\n",
      "User400000: Item recommendations:\n",
      "[ 362  467  715  862 1230 1355 1359 1465 1662 2111]\n",
      "User410000: Item recommendations:\n",
      "[ 171  498  706  914  977 1163 1238 1899 2045 2308]\n",
      "User420000: Item recommendations:\n",
      "[  28  379  417  925 1363 1370 1641 1758 1766 1927]\n",
      "User430000: Item recommendations:\n",
      "[ 513  560  713  887  909 1206 1798 1812 1839 2022]\n",
      "User440000: Item recommendations:\n",
      "[ 246  642  779  803  988 1118 1451 1616 2132 2137]\n",
      "User450000: Item recommendations:\n",
      "[ 573  879 1050 1078 1343 1378 1520 1955 2032 2126]\n",
      "User460000: Item recommendations:\n",
      "[ 139  201  969 1126 1135 1413 1824 1838 1961 1998]\n",
      "User470000: Item recommendations:\n",
      "[  14  765  808 1106 1210 1499 1647 2086 2145 2220]\n",
      "User480000: Item recommendations:\n",
      "[ 420  557  636 1004 1326 1411 1517 1717 1974 2149]\n",
      "User490000: Item recommendations:\n",
      "[ 318  601  747  905 1028 1083 1247 1603 1725 1772]\n",
      "User500000: Item recommendations:\n",
      "[ 131  152  269  794  797  843  922 1573 1916 2027]\n",
      "User510000: Item recommendations:\n",
      "[ 798  895 1378 1558 1909 2095 2265 2275 2283 2296]\n",
      "User520000: Item recommendations:\n",
      "[ 115  347  374  403 1398 1466 1590 1627 1677 2133]\n",
      "User530000: Item recommendations:\n",
      "[  33  148  494  687 1011 1028 1083 1407 1735 2224]\n",
      "User540000: Item recommendations:\n",
      "[ 122  380  447  811  865 1017 1505 1654 2123 2310]\n",
      "User550000: Item recommendations:\n",
      "[ 513  599  887  893 1587 1671 1735 1798 2022 2224]\n",
      "User560000: Item recommendations:\n",
      "[ 101  467  715  862 1275 1355 1465 1662 2094 2312]\n",
      "User570000: Item recommendations:\n",
      "[ 133  560  867  887  905 1102 1206 1489 1603 1859]\n",
      "User580000: Item recommendations:\n",
      "[ 251  624  659  705  794 1208 1273 1402 2192 2261]\n",
      "User590000: Item recommendations:\n",
      "[ 141  171  428  706  895 1430 1848 1999 2296 2308]\n",
      "User600000: Item recommendations:\n",
      "[ 151  222  364  499  633  835  864 1452 1908 2211]\n",
      "User610000: Item recommendations:\n",
      "[ 148  433  440  494  771 1044 1284 1389 2224 2288]\n",
      "User620000: Item recommendations:\n",
      "[ 742  829  853  962 1116 1183 1356 1432 1787 2149]\n",
      "User630000: Item recommendations:\n",
      "[ 293  547  650  654  921 1233 1427 2044 2261 2296]\n",
      "User640000: Item recommendations:\n",
      "[ 208  396 1203 1278 1302 1451 1568 1925 2127 2323]\n",
      "User650000: Item recommendations:\n",
      "[ 239  990 1216 1220 1359 1607 1616 1724 1943 2205]\n",
      "User660000: Item recommendations:\n",
      "[  31  674  887 1088 1292 1587 1798 1837 2083 2320]\n",
      "User670000: Item recommendations:\n",
      "[   8  528  538  670  876 1487 1540 1631 1800 2191]\n",
      "User680000: Item recommendations:\n",
      "[   8  457  672  760 1240 1631 1716 1805 1854 1904]\n",
      "User690000: Item recommendations:\n",
      "[ 115  627  994 1259 1677 1962 2020 2257 2266 2284]\n",
      "User700000: Item recommendations:\n",
      "[ 143  374 1075 1249 1423 1462 1704 1823 1912 2133]\n",
      "User710000: Item recommendations:\n",
      "[  60  461  619  715 1338 1691 2026 2094 2153 2201]\n",
      "User720000: Item recommendations:\n",
      "[ 440  610  902 1163 1482 1609 1618 1784 1868 2323]\n",
      "User730000: Item recommendations:\n",
      "[ 599  644  902 1284 1389 1482 1776 2022 2045 2214]\n",
      "User740000: Item recommendations:\n",
      "[  72  154  257  698  890  919 1353 1874 2270 2313]\n",
      "User750000: Item recommendations:\n",
      "[ 515  965 1216 1607 1724 1919 1925 1943 2186 2251]\n"
     ]
    }
   ],
   "source": [
    "# Pull user features out of the user features matrix and predict for just all users\n",
    "for user in range(0, n_users, 10000):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    print(\"User\"+str(user)+\": Item recommendations:\")\n",
    "    print(u_top_ten_recs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Internal IDs back to the original IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 10002: Item recommendations:\n",
      "751025\n",
      "330011\n",
      "538056\n",
      "506003\n",
      "866213\n",
      "304123\n",
      "701006\n",
      "843001\n",
      "194032\n",
      "381017\n",
      "User 10006: Item recommendations:\n",
      "860130\n",
      "774263\n",
      "430001\n",
      "202040\n",
      "596243\n",
      "498009\n",
      "157003\n",
      "454005\n",
      "316124\n",
      "440010\n",
      "User 10011: Item recommendations:\n",
      "204004\n",
      "872007\n",
      "322002\n",
      "148005\n",
      "478049\n",
      "968002\n",
      "146013\n",
      "806022\n",
      "825021\n",
      "803005\n",
      "User 10036: Item recommendations:\n",
      "774253\n",
      "204008\n",
      "103239\n",
      "310033\n",
      "752489\n",
      "999001\n",
      "825002\n",
      "520006\n",
      "808008\n",
      "809025\n",
      "User 10039: Item recommendations:\n",
      "317205\n",
      "105074\n",
      "869020\n",
      "290062\n",
      "240002\n",
      "493015\n",
      "865028\n",
      "185004\n",
      "538008\n",
      "930004\n"
     ]
    }
   ],
   "source": [
    "for user in range(5):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    print(\"User \"+str(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)])+\": Item recommendations:\")\n",
    "    #print(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)]) \n",
    "    for m in u_top_ten_recs:\n",
    "        print(list(idfam1_to_internal_item_ids.keys())[list(idfam1_to_internal_item_ids.values()).index(m)]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and writing a resulting CSV for recommendations for all users in the input database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100.9209020137787\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "HybridRecommendations=pd.DataFrame([])\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for user in range(n_users):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    if user %100 ==0 :\n",
    "        print(user)\n",
    "    user_id =str(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)])\n",
    "    for m in u_top_ten_recs:\n",
    "        items = (list(idfam1_to_internal_item_ids.keys())[list(idfam1_to_internal_item_ids.values()).index(m)]) \n",
    "        HybridRecommendations=HybridRecommendations.append(pd.DataFrame({'itemId': items,'userId': user_id}, index=[0]), ignore_index=True)\n",
    "t2 = time.time()\n",
    "total = t2-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:20, 80.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2242.513892173767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t2 = time.time()\n",
    "idfam1_to_internal_item_ids_REVERSE = {}\n",
    "for key, value in idfam1_to_internal_item_ids.items():\n",
    "    idfam1_to_internal_item_ids_REVERSE[value] = key\n",
    "k = 10\n",
    "\n",
    "from numpy import *\n",
    "u_features = sparse.csr_matrix(full_user_features)\n",
    "u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)\n",
    "    \n",
    "result = [list(flatnonzero(row  <= k)) for row in u_rankings]\n",
    "result = numpy.matrix(result)\n",
    "result = pd.DataFrame(result, columns=[ 'item' + str( i+1) for i in range(k)] )\n",
    "result['userId'] = idcte_to_internal_user_ids.keys()\n",
    "result = pd.melt(result, id_vars=['userId'], value_vars=[ 'item' + str( i+1) for i in range(k)])\n",
    "del result['variable']\n",
    "result = result.rename(columns={\"value\": \"itemId\"})\n",
    "result['itemId'] = result['itemId'].apply( lambda x: idfam1_to_internal_item_ids_REVERSE[x])\n",
    "result\n",
    "table_id = 'Resultados.test_tensorrec_04_porciento_17_junio_2020'\n",
    "result.to_gbq(table_id, project_id='rmf2gcp')\n",
    "t3 = time.time()\n",
    "total = t3-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>751025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006</td>\n",
       "      <td>860130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10011</td>\n",
       "      <td>204004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10036</td>\n",
       "      <td>774253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10039</td>\n",
       "      <td>317205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId\n",
       "0   10002  751025\n",
       "1   10006  860130\n",
       "2   10011  204004\n",
       "3   10036  774253\n",
       "4   10039  317205"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Recommender can also be used to predict similar items given some item IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 1.0),\n",
       "  (562, 0.99641275),\n",
       "  (1368, 0.9796147),\n",
       "  (1425, 0.97903633),\n",
       "  (868, 0.9783392),\n",
       "  (1217, 0.9761654),\n",
       "  (1148, 0.97548115),\n",
       "  (558, 0.95853096),\n",
       "  (929, 0.95253736),\n",
       "  (576, 0.9509862)],\n",
       " [(55, 0.9999999),\n",
       "  (579, 0.9783963),\n",
       "  (1495, 0.97485507),\n",
       "  (1713, 0.96817),\n",
       "  (861, 0.9578448),\n",
       "  (2221, 0.95660573),\n",
       "  (1901, 0.94763094),\n",
       "  (518, 0.93635976),\n",
       "  (1719, 0.92928034),\n",
       "  (1478, 0.92869)],\n",
       " [(90, 0.9999999),\n",
       "  (2031, 0.99387604),\n",
       "  (2201, 0.9642502),\n",
       "  (249, 0.9590916),\n",
       "  (2061, 0.95707124),\n",
       "  (420, 0.9558236),\n",
       "  (146, 0.9461703),\n",
       "  (1717, 0.9457096),\n",
       "  (737, 0.9420463),\n",
       "  (461, 0.9298396)]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model.predict_similar_items(item_features=item_indicator_features,item_ids=[3,55,90], n_similar=10) #sera util para los usuarios de compra en efectivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7594280, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.36666666666667"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2242/60 # ocupo 40 gb de RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
