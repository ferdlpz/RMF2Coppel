{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "#!pip install pyspark\n#!pip install --upgrade google-cloud-bigquery[pandas]\n#!pip install pyspark[sql] #PARSEO RAPIDO DE PANDAS A SPARK RDDSQL"}, {"cell_type": "markdown", "metadata": {}, "source": "### Importing the libraries and starting the Spark Session"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "import pyspark.sql.functions as sql_func\nfrom pyspark.sql.types import *\nfrom pyspark.ml.recommendation import ALS, ALSModel\nfrom pyspark.context import SparkContext \nfrom pyspark.sql import SparkSession\nfrom pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\nfrom pyspark.ml.evaluation import RegressionEvaluator\nimport pandas as pd"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "#!export ARROW_PRE_0_15_IPC_FORMAT=1\n#!echo $ARROW_PRE_0_15_IPC_FORMAT"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "sc = SparkContext.getOrCreate()"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "spark = SparkSession(sc)\nspark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "#from pyspark.context import \nspark = SparkSession(sc)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Add asset from remote connection "}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": "final_stat = None"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\nFROM `rmf2gcp.RawData.Workflow_aggregado`\nWHERE id_table_dem <= 189857\n"}], "source": "# Get data from GCP- BQ\nfrom google.cloud import bigquery\nimport time\nt0 = time.time()\n\nporcentaje = 1\nlimite = int(189857 * porcentaje)\n\ndef get_data_BQ(sql):\n    client = bigquery.Client()\n    df = client.query(sql).to_dataframe()\n    return(df)\nsql =  '''SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\nFROM `rmf2gcp.RawData.Workflow_aggregado`\nWHERE id_table_dem <= ''' + str(limite) #310 588 606 ''' # corre en mi local y pesa 56MB %1 del total de la muestra\nprint(sql)"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": "final_stat = get_data_BQ(sql)"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "ID_CTE       int64\nID_CLAS1     int64\nFREQUENCY    int64\ndtype: object\n(3817915, 3)\n"}], "source": "print(final_stat.dtypes)\nprint(final_stat.shape)"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/usr/lib/spark/python/pyspark/sql/session.py:714: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n  An error occurred while calling z:org.apache.spark.sql.api.python.PythonSQLUtils.readArrowStreamFromFile.\n: java.lang.IllegalArgumentException\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:334)\n\tat org.apache.arrow.vector.ipc.message.MessageSerializer.readMessage(MessageSerializer.java:543)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$$anon$3.readNextBatch(ArrowConverters.scala:243)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$$anon$3.<init>(ArrowConverters.scala:229)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$.getBatchesFromStream(ArrowConverters.scala:228)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$.$anonfun$readArrowStreamFromFile$2(ArrowConverters.scala:216)\n\tat org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2543)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$.readArrowStreamFromFile(ArrowConverters.scala:214)\n\tat org.apache.spark.sql.api.python.PythonSQLUtils$.readArrowStreamFromFile(PythonSQLUtils.scala:46)\n\tat org.apache.spark.sql.api.python.PythonSQLUtils.readArrowStreamFromFile(PythonSQLUtils.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\nAttempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true.\n  warnings.warn(msg)\n"}, {"name": "stdout", "output_type": "stream", "text": "+------+--------+---------+\n|ID_CTE|ID_CLAS1|FREQUENCY|\n+------+--------+---------+\n|945723|  314156|        7|\n|550294|  319062|        6|\n|262907|  314064|        6|\n|681339|  224009|        6|\n|191358|  313152|        7|\n+------+--------+---------+\nonly showing top 5 rows\n\n"}], "source": "final_stat = spark.createDataFrame(final_stat)\nfinal_stat.show(5)"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pyspark.sql.dataframe.DataFrame'>\n"}], "source": "final_stat.count()\nprint(type(final_stat))"}, {"cell_type": "markdown", "metadata": {}, "source": "### Preparing data for the model"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": "ratings = (final_stat\n    .select(\n        'ID_CTE',\n        'ID_CLAS1',\n        'FREQUENCY',\n    )\n).cache()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Spliting the data set to test and train for measuring the performance of the ALS Model"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": "(training, test) = ratings.randomSplit([0.8, 0.2])"}, {"cell_type": "markdown", "metadata": {}, "source": "### Build the recommendation model using ALS on the training data\n"}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Root-mean-square error = 1.5968087153882395\n"}], "source": "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\nals = ALS(maxIter=2, regParam=0.01, \n          userCol=\"ID_CTE\", itemCol=\"ID_CLAS1\", ratingCol=\"FREQUENCY\",\n          coldStartStrategy=\"drop\",\n          implicitPrefs=True)\n\nmodel = als.fit(ratings)\n\n# Evaluate the model by computing the RMSE on the test data\npredictions = model.transform(test)\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"FREQUENCY\",\n                                predictionCol=\"prediction\")\n\nrmse = evaluator.evaluate(predictions)\nprint(\"Root-mean-square error = \" + str(rmse))"}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+--------+---------+------------+\n|ID_CTE|ID_CLAS1|FREQUENCY|  prediction|\n+------+--------+---------+------------+\n|408865|  212010|        1| 3.639931E-4|\n|144771|  432399|        1| 0.002300021|\n|652912|  432399|        1| 0.002555012|\n|343446|  432399|        1|  0.00508264|\n|837641|  432399|        2|0.0029049083|\n+------+--------+---------+------------+\nonly showing top 5 rows\n\n"}], "source": "predictions.show(5)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Parameters of ALS Model in PySpark realization are following:\n\n##### NumBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation.\n##### rank is the number of latent factors in the model.\n##### maxIter is the maximum number of iterations to run.\n##### regParam specifies the regularization parameter in ALS.\n##### implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).\n##### alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0)"}, {"cell_type": "markdown", "metadata": {}, "source": "###  Generate top 10 Item recommendations for each user\n\n"}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "189857\n+------+--------------------+\n|ID_CTE|     recommendations|\n+------+--------------------+\n| 10362|[[318073, 0.09074...|\n| 11033|[[701305, 0.65940...|\n| 11141|[[102016, 0.27780...|\n| 12940|[[313152, 0.74259...|\n| 13832|[[318009, 0.51142...|\n+------+--------------------+\nonly showing top 5 rows\n\n"}], "source": "userRecs = model.recommendForAllUsers(10)\nprint(userRecs.count())\nuserRecs.show(5)"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"data": {"text/plain": "[Row(ID_CTE=10362, recommendations=[Row(ID_CLAS1=318073, rating=0.09074781835079193), Row(ID_CLAS1=224009, rating=0.08243425190448761), Row(ID_CLAS1=862009, rating=0.07791068404912949), Row(ID_CLAS1=318203, rating=0.06855244934558868), Row(ID_CLAS1=229032, rating=0.05686267465353012), Row(ID_CLAS1=106003, rating=0.05195869132876396), Row(ID_CLAS1=106001, rating=0.05104609951376915), Row(ID_CLAS1=701305, rating=0.04754101485013962), Row(ID_CLAS1=229011, rating=0.04433450847864151), Row(ID_CLAS1=101028, rating=0.04307369515299797)]),\n Row(ID_CTE=11033, recommendations=[Row(ID_CLAS1=701305, rating=0.6594046950340271), Row(ID_CLAS1=862009, rating=0.5082660913467407), Row(ID_CLAS1=381009, rating=0.4194330871105194), Row(ID_CLAS1=423132, rating=0.34522974491119385), Row(ID_CLAS1=318009, rating=0.3161504566669464), Row(ID_CLAS1=319059, rating=0.31468671560287476), Row(ID_CLAS1=380073, rating=0.30177468061447144), Row(ID_CLAS1=380283, rating=0.30172455310821533), Row(ID_CLAS1=290059, rating=0.2808142304420471), Row(ID_CLAS1=862008, rating=0.2624112367630005)])]"}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": "userRecs.take(2)"}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|     recommendations|\n+--------------------+\n|[[318073, 0.09074...|\n|[[701305, 0.65940...|\n|[[102016, 0.27780...|\n|[[313152, 0.74259...|\n|[[318009, 0.51142...|\n|[[862009, 0.54229...|\n|[[701305, 0.64938...|\n|[[102011, 0.25774...|\n|[[295019, 0.55509...|\n|[[701305, 1.21820...|\n|[[314156, 0.54998...|\n|[[318073, 0.71593...|\n|[[106010, 0.08245...|\n|[[102016, 0.24529...|\n|[[862009, 0.46045...|\n|[[224009, 0.67586...|\n|[[314063, 0.59726...|\n|[[106055, 0.22423...|\n|[[862009, 1.05049...|\n|[[862009, 0.63242...|\n+--------------------+\nonly showing top 20 rows\n\n"}], "source": "userRecs[['recommendations']].show()"}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [{"data": {"text/plain": "1"}, "execution_count": 20, "metadata": {}, "output_type": "execute_result"}], "source": "1"}, {"cell_type": "markdown", "metadata": {}, "source": "### Display the recommendations and get them in the correct format"}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+--------------------+\n|ID_CTE|     recommendations|\n+------+--------------------+\n| 10362|[318073, 0.09074782]|\n| 10362|[224009, 0.08243425]|\n| 10362|[862009, 0.077910...|\n| 10362|[318203, 0.06855245]|\n+------+--------------------+\nonly showing top 4 rows\n\n"}], "source": "from pyspark.sql.functions import explode\nuserRecs1=userRecs.withColumn(\"recommendations\", explode(userRecs.recommendations))\nuserRecs1.show(4)"}, {"cell_type": "markdown", "metadata": {}, "source": "####  Breaking down reach recommendation to separate columns"}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": "userRecs1= userRecs1.select('ID_CTE', 'recommendations.*')       "}, {"cell_type": "markdown", "metadata": {}, "source": "### Display the results"}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+--------+----------+\n|ID_CTE|ID_CLAS1|    rating|\n+------+--------+----------+\n| 10362|  318073|0.09074782|\n| 10362|  224009|0.08243425|\n+------+--------+----------+\nonly showing top 2 rows\n\n"}], "source": "userRecs1.show(2) "}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [{"data": {"text/plain": "1898570"}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}], "source": "userRecs1.count()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Writing the Output back to the Remote Datasource"}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[ID_CTE: int, ID_CLAS1: int, rating: float]"}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": "final_stat = userRecs1.toPandas()\nuserRecs1.unpersist(True)"}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Collecting pandas_gbq\n  Downloading https://files.pythonhosted.org/packages/53/f3/3100eb9332c62c5e5ac486d5421965da23a0b92012825bfbb372b7f8d508/pandas_gbq-0.13.2-py3-none-any.whl\nRequirement already satisfied: setuptools in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (41.4.0)\nRequirement already satisfied: pandas>=0.19.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (1.0.4)\nRequirement already satisfied: google-auth-oauthlib in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (0.4.1)\nRequirement already satisfied: google-cloud-bigquery>=1.11.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (1.25.0)\nRequirement already satisfied: google-auth in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (1.17.2)\nCollecting pydata-google-auth (from pandas_gbq)\n  Downloading https://files.pythonhosted.org/packages/0b/dc/be321b769b761ec2640f1e4561c2953dd6a4a3efe6b10b5781774c71177a/pydata_google_auth-1.1.0-py2.py3-none-any.whl\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas>=0.19.0->pandas_gbq) (2019.3)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas>=0.19.0->pandas_gbq) (2.8.0)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas>=0.19.0->pandas_gbq) (1.17.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth-oauthlib->pandas_gbq) (1.3.0)\nRequirement already satisfied: six<2.0.0dev,>=1.13.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (1.15.0)\nRequirement already satisfied: google-resumable-media<0.6dev,>=0.5.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (0.5.1)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (3.12.2)\nRequirement already satisfied: google-api-core<2.0dev,>=1.15.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (1.20.0)\nRequirement already satisfied: google-cloud-core<2.0dev,>=1.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (1.3.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth->pandas_gbq) (4.1.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth->pandas_gbq) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth->pandas_gbq) (4.6)\nRequirement already satisfied: requests>=2.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (2.23.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (3.1.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery>=1.11.1->pandas_gbq) (1.52.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth->pandas_gbq) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (2019.9.11)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (1.24.2)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (2.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (3.0.4)\nInstalling collected packages: pydata-google-auth, pandas-gbq\nSuccessfully installed pandas-gbq-0.13.2 pydata-google-auth-1.1.0\n"}], "source": "!pip install pandas_gbq"}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [{"data": {"text/plain": "'Resultados.test_spark_01porciento_17_junio_2020'"}, "execution_count": 27, "metadata": {}, "output_type": "execute_result"}], "source": "table_id = 'Resultados.test_spark_0'+str(porcentaje)+'porciento_17_junio_2020'\ntable_id"}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "1it [00:31, 31.58s/it]"}, {"name": "stdout", "output_type": "stream", "text": "424.23178482055664\n"}, {"name": "stderr", "output_type": "stream", "text": "\n"}], "source": "final_stat.to_gbq(table_id, project_id='rmf2gcp')\nt3 = time.time()\ntotal = t3-t0\nprint(total)"}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [], "source": "#!mkdir test/"}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [], "source": "#final_stat.to_csv('test_spark_0'+str(porcentaje)+'porciento_17_junio_2020')"}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [], "source": "#!gsutil cp test_gcp_cluster_10_junio_2020.csv gs://resultadosrmf2/prueba_gcp_01porciento/test_local_10_junio_2020.csv"}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [], "source": "#!zip test_gcp_cluster_10_junio_2020.csv.zip test_gcp_cluster_10_junio_2020.csv"}, {"cell_type": "code", "execution_count": 33, "metadata": {}, "outputs": [], "source": "#!ls"}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [], "source": "#!gsutil cp test_gcp_cluster_10_junio_2020.csv.zip gs://resultadosrmf2/prueba_gcp_01porciento/test_local_10_junio_2020.csv.zip"}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [], "source": "##!rm -r test_modelos\n#!mkdir test_modelos_gcp\n#!chmod 777 test_modelos_gcp"}, {"cell_type": "code", "execution_count": 36, "metadata": {}, "outputs": [], "source": "#from pyspark.ml import Pipeline"}, {"cell_type": "code", "execution_count": 37, "metadata": {}, "outputs": [], "source": "#pipeline = Pipeline(stages=[model])"}, {"cell_type": "code", "execution_count": 38, "metadata": {}, "outputs": [], "source": "#model_alsWML = pipeline.fit(ratings)"}, {"cell_type": "code", "execution_count": 39, "metadata": {}, "outputs": [], "source": "#model_alsWML.save('/test_modelos_gcp/')"}, {"cell_type": "code", "execution_count": 40, "metadata": {}, "outputs": [], "source": "#!ls -la"}, {"cell_type": "code", "execution_count": 41, "metadata": {}, "outputs": [], "source": "#!gsutil cp test_gcp_cluster_10_junio_2020.csv.zip gs://resultadosrmf2/prueba_gcp_01porciento/test_local_10_junio_2020.csv.zip"}], "metadata": {"environment": {"name": "tf-gpu.1-15.m48", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m48"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}