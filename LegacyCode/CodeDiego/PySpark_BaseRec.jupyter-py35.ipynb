{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sql_func\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+----------+\n",
      "| ID_CTE|ID_FAM1|FREQ|YEAR-MONTH|\n",
      "+-------+-------+----+----------+\n",
      "|1369361|1106234|   1|2017-10-01|\n",
      "|1421660|1862009|   1|2017-10-01|\n",
      "|1453179|1102164|   1|2017-10-01|\n",
      "|1455817|1854022|   1|2017-10-01|\n",
      "|1459605|1310121|   1|2017-10-01|\n",
      "+-------+-------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#final_stat = spark.read.csv('/user-home/libraries/raw_data/datasets/Base_rec.csv', header=True, sep='|')\n",
    "final_stat = spark.read.csv('/user-home/libraries/Sampled_data/datasets/dec16-nov17_Jalisco.csv', header=True, sep=',')  #test for Jalisco for comparison (@DA)\n",
    "\n",
    "final_stat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (final_stat\n",
    "    .select(\n",
    "        'ID_CTE',\n",
    "        'ID_FAM1',\n",
    "        'FREQ',\n",
    "    )\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "ratings= ratings.withColumn(\"ID_CTE\", expr(\"CAST(ID_CTE AS INTEGER)\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings=ratings.withColumn(\"ID_FAM1\", expr(\"CAST(ID_FAM1 AS INTEGER)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings=ratings.withColumn(\"FREQ\", expr(\"CAST(FREQ AS INTEGER)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CTE', 'int'), ('ID_FAM1', 'int'), ('FREQ', 'int')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.00728276362509358\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=10, regParam=0.01,rank=100, \n",
    "          userCol=\"ID_CTE\", itemCol=\"ID_FAM1\", ratingCol=\"FREQ\",\n",
    "          #coldStartStrategy=\"drop\",\n",
    "          implicitPrefs=False)\n",
    "\n",
    "model = als.fit(ratings)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"FREQ\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 11 µs, total: 17 µs\n",
      "Wall time: 21.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1902"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate top 10 Item recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "userRecs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|  ID_CTE|     recommendations|\n",
      "+--------+--------------------+\n",
      "|40354130| [1282002,0.9973844]|\n",
      "|40354130| [1401002,0.9152835]|\n",
      "|40354130|[1594184,0.90924096]|\n",
      "|40354130| [1105007,0.5333132]|\n",
      "|40354130| [1775262,0.4785588]|\n",
      "|40354130|[1291062,0.46936402]|\n",
      "|40354130|[1863047,0.44844317]|\n",
      "|40354130| [1594185,0.4394519]|\n",
      "|40354130|[1290059,0.43123487]|\n",
      "|40354130|[1432043,0.41803825]|\n",
      "|30396781| [2224033,1.0009017]|\n",
      "|30396781|[2295019,0.99868584]|\n",
      "|30396781| [2229035,0.9914556]|\n",
      "|30396781| [2299099,0.9599417]|\n",
      "|30396781| [2229032,0.8849272]|\n",
      "|30396781| [2224041,0.7363132]|\n",
      "|30396781| [2224073,0.7150184]|\n",
      "|30396781| [2229003,0.7150184]|\n",
      "|30396781|[2295027,0.65394366]|\n",
      "|30396781| [2295026,0.6280386]|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "userRecs1=userRecs.withColumn(\"recommendations\", explode(userRecs.recommendations))\n",
    "userRecs1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import select as s\n",
    "#userRecs1=\n",
    "userRecs1= userRecs1 \\\n",
    "  .select('ID_CTE', 'recommendations.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs1.coalesce(1).write.format(\"csv\").option(\"header\", \"true\").save('/user-home/libraries/Sampled_data/datasets/JaliscoResult.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
