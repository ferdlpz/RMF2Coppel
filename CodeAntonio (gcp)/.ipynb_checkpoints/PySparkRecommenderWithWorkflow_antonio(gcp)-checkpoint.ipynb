{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow demonstration with a recommender engine on a sampled dataset from Transactions.csv using ALS Model\n",
    "### This is the notebook for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries and starting the Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sql_func\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.context import SparkContext \n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc =SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.context import \n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add asset from remote connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dsx_core_utils, requests, os, io\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "final_stat = None\n",
    "#dataSet = dsx_core_utils.get_remote_data_set_info('TRANSACTIONS')\n",
    "#dataSource = dsx_core_utils.get_data_source_info(dataSet['datasource'])\n",
    "#sparkSession = SparkSession(sc).builder.getOrCreate()\n",
    "## Load JDBC data to Spark dataframe\n",
    "#dbTableOrQuery = '\"' + (dataSet['schema'] + '\".\"' if(len(dataSet['schema'].strip()) != 0) else '') + dataSet['table'] + '\"'\n",
    "#if (dataSet['query']):\n",
    " #   dbTableOrQuery = \"(\" + dataSet['query'] + \") TBL\"\n",
    "#final_stat = sparkSession.read.format(\"jdbc\").option(\"url\", dataSource['URL']).option(\"dbtable\", dbTableOrQuery).option(\"user\",dataSource['user']).option(\"password\",dataSource['password']).load()\n",
    "#final_stat.show(5)\n",
    "\n",
    "####### VAMOS A PROBARLO LOCALMENTE CON LA TABLE DE bq dec16-nov17_Jalisco.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from GCP- BQ\n",
    "'''SELECT * \n",
    "FROM `rmf2gcp.RawData.Workflow_aggregado`\n",
    "limit 31058860#310 588 606 ''' # corre en mi local y pesa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (final_stat\n",
    "    .select(\n",
    "        'ID_CTE',\n",
    "        'ID_CLAS1',\n",
    "        'FREQUENCY',\n",
    "    )\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.limit(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data set to test and train for measuring the performance of the ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the recommendation model using ALS on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=2, regParam=0.01, \n",
    "          userCol=\"ID_CTE\", itemCol=\"ID_CLAS1\", ratingCol=\"FREQUENCY\",\n",
    "          coldStartStrategy=\"drop\",\n",
    "          implicitPrefs=True)\n",
    "\n",
    "model = als.fit(ratings)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"FREQUENCY\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of ALS Model in PySpark realization are following:\n",
    "\n",
    "##### NumBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation.\n",
    "##### rank is the number of latent factors in the model.\n",
    "##### maxIter is the maximum number of iterations to run.\n",
    "##### regParam specifies the regularization parameter in ALS.\n",
    "##### implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).\n",
    "##### alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate top 10 Item recommendations for each user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = model.recommendForAllUsers(10)\n",
    "userRecs.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the recommendations and get them in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "userRecs1=userRecs.withColumn(\"recommendations\", explode(userRecs.recommendations))\n",
    "userRecs1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Breaking down reach recommendation to separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import select as s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "userRecs1= userRecs1 \\\n",
    "  .select('ID_CTE', 'recommendations.*')    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs1.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the Output back to the Remote Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table_name = 'RecommendationsResult'\n",
    "userRecs1.coalesce(1).write \\\n",
    "   .format(\"jdbc\") \\\n",
    "    .mode('overwrite') \\\n",
    "    .option(\"url\", dataSource['URL']) \\\n",
    "    .option(\"dbtable\", dataSet['schema']+\".\"+new_table_name) \\\n",
    "    .option(\"user\", dataSource['user']) \\\n",
    "    .option(\"password\", dataSource['password']) \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsx_ml.ml import save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alsWML = pipeline.fit(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(name = 'PySparkRecommenderPipeline',\n",
    "     model = model_alsWML,\n",
    "     test_data = ratings,\n",
    "     algorithm_type = 'Classification',\n",
    "     source='PySparkRecommenderWithWorkflow.ipynb',\n",
    "     description='Recommender using PySpark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
