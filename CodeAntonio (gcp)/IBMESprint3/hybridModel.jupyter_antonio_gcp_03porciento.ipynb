{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRec recommender engine:\n",
    "## Prototyping of a recommender system in Python using TensorRec including input data manipulation, algorithm design, and usage for prediction.\n",
    "\n",
    "#### TensorRec is a Python package for building recommender systems. A TensorRec recommender system consumes three pieces of input data: user features, item features, and interactions. Based on the user/item features, the system will predict which items to recommend. The interactions are used when fitting the model: predictions are compared to the interactions and a loss/penalty is calculated, which the system learns to decrease. As we prototype our system, we tackle three major situations: how we handle interactions, how we handle features, and how we structure the recommender itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*YotDpHjvGL8xK91ZggthbA.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/getting-started-with-recommender-systems-and-tensorrec-8f50a9943eef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw ratings load :Each row represents a single rating: one user and one item. We’ll be using these ratings(frequency of purchase of each item) as our interactions between the user and the product."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import six\n",
    "print(six.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!pip install --upgrade six==1.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import time\n",
    "t0 = time.time()\n",
    "limite = 189857*3 # 18,985,770  # corre en mi local %0.1 del total de la muestra\n",
    "\n",
    "# functions\n",
    "def get_data_BQ(sql):\n",
    "    client = bigquery.Client()\n",
    "    df = client.query(sql).to_dataframe()\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\n",
      "FROM `rmf2gcp.RawData.Workflow_aggregado`\n",
      "WHERE id_table_dem <=  569571 ORDER BY USERID\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10002, 665040, 1],\n",
       " [10002, 248001, 1],\n",
       " [10002, 219060, 1],\n",
       " [10002, 232021, 1],\n",
       " [10002, 222011, 1],\n",
       " [10002, 124002, 1],\n",
       " [10002, 229008, 1]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql =  '''SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\n",
    "FROM `rmf2gcp.RawData.Workflow_aggregado`\n",
    "WHERE id_table_dem <=  ''' + str(limite) + ''' ORDER BY USERID'''\n",
    "\n",
    "print(sql)\n",
    "raw_ratings = get_data_BQ(sql)\n",
    "raw_ratings = raw_ratings.values.tolist() # pues vamos a seguir su mala practica de hacer una lista de listas \n",
    "raw_ratings[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the input to map Item and User IDs to new internal IDs\n",
    "### The new internal IDs will be created by the defaultdict on insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569571\n",
      "2307\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "idcte_to_internal_user_ids = collections.defaultdict(lambda: len(idcte_to_internal_user_ids))\n",
    "idfam1_to_internal_item_ids = collections.defaultdict(lambda: len(idfam1_to_internal_item_ids))\n",
    "for row in raw_ratings:\n",
    "    row[0] = idcte_to_internal_user_ids[int(row[0])]\n",
    "    row[1] = idfam1_to_internal_item_ids[int(row[1])]\n",
    "    row[2] = float(row[2])    # esta operacion esta de más \n",
    "n_users = len(idcte_to_internal_user_ids)\n",
    "n_items = len(idfam1_to_internal_item_ids)\n",
    "print(n_users)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(665040, 0), (248001, 1), (219060, 2), (232021, 3), (222011, 4), (124002, 5), (229008, 6)]\n",
      "[(10002, 0), (10006, 1), (10011, 2), (10036, 3), (10039, 4), (10043, 5), (10047, 6)]\n"
     ]
    }
   ],
   "source": [
    "print( [ (key, value) for key, value  in idfam1_to_internal_item_ids.items() ][0:7])\n",
    "print( [ (key, value) for key, value  in idcte_to_internal_user_ids.items() ][0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import numpy \n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, we’ll break the ratings in to a training and test set by shuffling and splitting the ratings. Our prototypes will be trained on the training set, and we’ll evaluate their success using the test set. Splitting the train/test sets at random like this is crude, and there are more rigorous techniques for model evaluation, but it is quick and clear for the purposes of this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the ratings and split them in to train/test sets 80%/20%\n",
    "random.shuffle(raw_ratings)  # Shuffles the list in-place\n",
    "cutoff = int(.8 * len(raw_ratings))\n",
    "train_ratings = raw_ratings[:cutoff]\n",
    "test_ratings = raw_ratings[cutoff:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we reorganize these ratings in to a Scipy sparse matrix. In this matrix, every row represents a user and every column is an item. The [i, j]th value in this matrix is User i’s interaction with Item j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This method converts a list of (user, item, rating) to a sparse matrix\n",
    "def interactions_list_to_sparse_matrix(interactions):\n",
    "    users_column, items_column, ratings_column, = zip(*interactions)\n",
    "    return sparse.coo_matrix((ratings_column, (users_column, items_column)),\n",
    "                             shape=(n_users, n_items))\n",
    "\n",
    "\n",
    "# Create sparse matrices of interaction data\n",
    "sparse_train_ratings = interactions_list_to_sparse_matrix(raw_ratings)\n",
    "sparse_test_ratings = interactions_list_to_sparse_matrix(test_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<569571x2307 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11021877 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_train_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRec library runs on TensorFlow so we install a compatible version of TensorFlow \n",
    "### Both TensorFlow and TensorRec can be installed using !pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569571\n"
     ]
    }
   ],
   "source": [
    "#!pip install \"tensorflow==1.13.1\"\n",
    "print(n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.3-dlenv_tfe\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorrec --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter Prototype\n",
    "### A collaborative filter is an algorithm that learns which users have similar tastes and recommends items to a user based on what similar users have liked. A common way to do this is through matrix factorization. In matrix factorization, we have to learn two matrices (user representations and item representations) that, when multiplied together, approximate the interactions:\n",
    "#### TensorRec will perform matrix factorization by default if it is given only identity matrices as user/item features. These identity matrices are often called “indicator features.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training collaborative filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Construct indicator features for users and items\n",
    "user_indicator_features = sparse.identity(n_users)\n",
    "item_indicator_features = sparse.identity(n_items)\n",
    "\n",
    "# Build a matrix factorization collaborative filter model\n",
    "cf_model = tensorrec.TensorRec(n_components=5)\n",
    "\n",
    "# Fit the collaborative filter model\n",
    "print(\"Training collaborative filter\")\n",
    "cf_model.fit(interactions=sparse_train_ratings,\n",
    "             user_features=user_indicator_features,\n",
    "             item_features=item_indicator_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Graphs\n",
    "### One way we can configure our TensorRec system is by changing the loss graph. The loss graph takes in predictions and interactions and calculates a penalty (loss) that the system will try to decrease as it learns.\n",
    "#### WMRB, which stands for “weighted margin-rank batch,” works by taking a random sample of items the user hasn’t interacted with and comparing their predictions to items the user likes. Over time, this pushes items a user likes to the top of the rankings. We can try using different loss graphs like WARP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Let's try a new loss function: WMRB \n",
    "'''\n",
    "print(\"Training collaborative filter with WMRB loss\")\n",
    "ranking_cf_model = tensorrec.TensorRec(n_components=5,\n",
    "                                       loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "ranking_cf_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                     user_features=user_indicator_features,\n",
    "                     item_features=item_indicator_features,\n",
    "                     n_sampled_items=int(n_items *1))\n",
    "\n",
    "# Check the results of the WMRB MF CF model\n",
    "print(\"WMRB matrix factorization collaborative filter:\")\n",
    "predicted_ranks = ranking_cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                                item_features=item_indicator_features)\n",
    "                                                '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Metadata Features\n",
    "## To continue experimenting, we should try to make use of other data available to us. We will try using User Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT USERID, FEATURES, STATE\n",
      "FROM `rmf2gcp.RawData.demographics_features` \n",
      "WHERE id_table_dem <= 569571\n"
     ]
    }
   ],
   "source": [
    "# To improve the recommendations, lets read in the user demographic data\n",
    "sql = \"\"\"\n",
    "SELECT USERID, FEATURES, STATE\n",
    "FROM `rmf2gcp.RawData.demographics_features` \n",
    "WHERE id_table_dem <= \"\"\" + str(limite)\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     USERID FEATURES                      STATE\n",
      "0     10006   81,C,M  SINALOA                  \n",
      "1     10050   75,C,M  SINALOA                  \n",
      "2     10059   87,C,M  SINALOA                  \n",
      "3     10066   77,C,F  SINALOA                  \n",
      "4     10097   75,C,M  SINALOA                  \n",
      "..      ...      ...                        ...\n",
      "795   20397   63,S,M  SINALOA                  \n",
      "796   20405   80,C,F  SINALOA                  \n",
      "797   20407   84,S,F  SINALOA                  \n",
      "798   20438   74,C,M  SINALOA                  \n",
      "799   20440   75,C,M  SINALOA                  \n",
      "\n",
      "[800 rows x 3 columns]\n",
      "USERID       int64\n",
      "FEATURES    object\n",
      "STATE       object\n",
      "dtype: object\n",
      "Index(['USERID', 'FEATURES', 'STATE'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['USERID', 'FEATURES', 'STATE']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_user_metadata = get_data_BQ(sql)\n",
    "print(raw_user_metadata.head(800))\n",
    "print(raw_user_metadata.dtypes)\n",
    "print(raw_user_metadata.columns)\n",
    "raw_user_metadata_header = ['USERID', 'FEATURES', 'STATE']\n",
    "raw_user_metadata_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10006, '81,C,M', 'SINALOA                  '],\n",
       " [10050, '75,C,M', 'SINALOA                  '],\n",
       " [10059, '87,C,M', 'SINALOA                  '],\n",
       " [10066, '77,C,F', 'SINALOA                  '],\n",
       " [10097, '75,C,M', 'SINALOA                  '],\n",
       " [10104, '78,C,F', 'SINALOA                  '],\n",
       " [10110, '88,V,M', 'SINALOA                  ']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_user_metadata = raw_user_metadata.values.tolist()\n",
    "raw_user_metadata[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we’ll want to read this data, map the movies to our internal IDs, and keep track of the features for each user. Then we’ll binarize the feature  labels using Scikit’s MultiLabelBinarizer. The binarized output will be our features for our new recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw metadata example:\n",
      "['USERID', 'FEATURES', 'STATE']\n",
      "[2307, ['81', 'C', 'M'], 'SINALOA                  ']\n"
     ]
    }
   ],
   "source": [
    "# Map the features IDs to our internal IDs and keep track of the gender and age\n",
    "temp_string = ''\n",
    "temp_list = []\n",
    "count = 1\n",
    "user_id_by_internal_id = {}\n",
    "user_features_by_internal_id = {}\n",
    "for row in raw_user_metadata:\n",
    "    temp_string = ''\n",
    "    temp_list = []\n",
    "    \n",
    "\n",
    "    temp_string = str(row[0])\n",
    "    temp_list = row[1].split(',')\n",
    "    #print(count)\n",
    "    #print(temp_string)\n",
    "    #print(temp_list)\n",
    "    row[0] = idfam1_to_internal_item_ids[int(temp_string)]  # Map to IDs\n",
    "    row[1] = temp_list  # Split up\n",
    "    user_id_by_internal_id[temp_string] = temp_string\n",
    "    user_features_by_internal_id[int(temp_string)] = row[1]\n",
    "    count+=1\n",
    "# Look at an example user metadata row\n",
    "print(\"Raw metadata example:\\n{}\\n{}\".format(raw_user_metadata_header, \n",
    "                                             raw_user_metadata[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10006, ['81', 'C', 'M']),\n",
       " (10050, ['75', 'C', 'M']),\n",
       " (10059, ['87', 'C', 'M']),\n",
       " (10066, ['77', 'C', 'F']),\n",
       " (10097, ['75', 'C', 'M']),\n",
       " (10104, ['78', 'C', 'F']),\n",
       " (10110, ['88', 'V', 'M'])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (key, value) for key,value in user_features_by_internal_id.items() ][0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a list of features where the index is the internal user ID and the value is a list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = [user_features_by_internal_id[internal_id]\n",
    "                for internal_id in user_features_by_internal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['81', 'C', 'M'],\n",
       " ['75', 'C', 'M'],\n",
       " ['87', 'C', 'M'],\n",
       " ['77', 'C', 'F'],\n",
       " ['75', 'C', 'M'],\n",
       " ['78', 'C', 'F'],\n",
       " ['88', 'V', 'M']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "29 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the features into binarized labels using scikit's MultiLabelBinarizer\n",
    "user_features = MultiLabelBinarizer().fit_transform(user_feat)\n",
    "n_features = user_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 #perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coerce the user features to a sparse matrix, which TensorRec expects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<569571x96 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1708713 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_mat = sparse.coo_matrix(user_features)\n",
    "user_features_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s not as good as the ranking collaborative filter but it’s significantly more effective if we add it to the base collaborative filter.\n",
    "#### There is a major weakness to this system: user feature alone are not very descriptive and are not enough information to make an informed recommendation. If we had more descriptive metadata and item metadata (views, clicks, basket information etc.) we may have more success with this content-based recommender system.\n",
    "#### On the other hand, there is a major strength to this system: by relying on only metadata features, and not using indicator features, we can recommend products which were not present when training the model. Similarly, if we have valuable user metadata we can avoid using user indicator features and make predictions for users who’ve never interacted with a product before. This is called “cold-start” recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid recommender: \n",
    "## Hybrid recommender systems combine two or more recommendation strategies in different ways to benefit from their complementary advantages.\n",
    "### Let’s combine these two: we’ll use indicator features to get the strengths of a collaborative filter, and we’ll also use the content features to take advantage of the metadata. This combination of collaborative filtering and content-based recommendation is the hybrid model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do this by stacking the two sets of features together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<569571x569667 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2278284 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try concatenating the user features on to the indicator features for a hybrid recommender system\n",
    "full_user_features = sparse.hstack([user_indicator_features, user_features_mat])\n",
    "full_user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:n_sampled_items was specified, but the loss graph is not sample-based\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hybrid recommender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Training hybrid recommender\")\n",
    "hybrid_model = tensorrec.TensorRec(\n",
    "    n_components=5\n",
    ")\n",
    "hybrid_model.fit(interactions=sparse_train_ratings,\n",
    "                 user_features=full_user_features,\n",
    "                 item_features=item_indicator_features,\n",
    "                 n_sampled_items=int(n_items * .01))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This performs the best even though we are using trivial features from users. If we have more metadata, we can expect larger impact of the Hybrid recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid recommender:\n",
      "Performance metrics: Train: 0.0218 Test: 0.0238\n"
     ]
    }
   ],
   "source": [
    "print(\"Hybrid recommender:\")\n",
    "predicted_ranks = hybrid_model.predict_rank(user_features=full_user_features,\n",
    "                                            item_features=item_indicator_features)\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Performance metrics: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the model: first prototype\n",
    "#### To do this, we’ll look at a metric called “recall at K.” Recall@K says, for the average user, what percentage of their test items made it in to the top K in the predicted rankings.\n",
    "#### Recall@K is a nice metric for many recommender systems because it emulates the behavior of a recommendation product. Before calculating the recall, we’ll want to decide which interactions should count as a “purchased item.” In this case, choose to use all ratings of at least 1.0 as “liked products” and ignore the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factorization collaborative filter:\n",
      "Performance metrics: Train: 0.0044 Test: 0.0044\n"
     ]
    }
   ],
   "source": [
    "# Create sets of train/test interactions that are only frequency > 1 since these represent the products that have been purchased \n",
    "sparse_train_ratings_1plus = sparse_train_ratings.multiply(sparse_train_ratings >= 1)\n",
    "sparse_test_ratings_1plus = sparse_test_ratings.multiply(sparse_test_ratings >= 1)\n",
    "\n",
    "\n",
    "# This method consumes item ranks for each user and prints out train/test metrics\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Performance metrics: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "\n",
    "# Check the results of the MF CF model\n",
    "print(\"Matrix factorization collaborative filter:\")\n",
    "predicted_ranks = cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                        item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "38 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "39 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43 #perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Recommendation\n",
    "### Now that we have metadata about our user, one thing we can try is to recommend based solely on the user metadata.\n",
    "### To do this, we will configure a TensorRec model to use a pass-through representation graph for item features. For us, this means that the user representations will be the same as the user features that are passed in (just the user information like gender, age etc.) and the item representations will reflect how much the item suits that particular set of user features.\n",
    "#### Ideal case is when we would have item metadata as well: because that would have a greater impact on making the recommendation better- also help solving the cold start problem. There is a major weakness to this system: these features alone are not very descriptive and are not enough information to make an informed recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training content-based recommender\n"
     ]
    }
   ],
   "source": [
    "# Fit a content-based model using the user features\n",
    "print(\"Training content-based recommender\")\n",
    "content_model = tensorrec.TensorRec(\n",
    "    n_components=n_features,\n",
    "   user_repr_graph=tensorrec.representation_graphs.FeaturePassThroughRepresentationGraph()\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:n_sampled_items was specified, but the loss graph is not sample-based\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "content_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                  user_features=user_features_mat,\n",
    "                  item_features=item_indicator_features,\n",
    "                  n_sampled_items=int(n_items * .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-based recommender:\n",
      "Performance metrics: Train: 0.0252 Test: 0.0271\n"
     ]
    }
   ],
   "source": [
    "# Check the results of the content-based model\n",
    "print(\"Content-based recommender:\")\n",
    "predicted_ranks = content_model.predict_rank(user_features=user_features_mat,\n",
    "                                             item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48 # perdido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49 # perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s not as good as the ranking collaborative filter but it’s significantly more effective if we add it to the base collaborative filter.\n",
    "#### There is a major weakness to this system: user feature alone are not very descriptive and are not enough information to make an informed recommendation. If we had more descriptive metadata and item metadata (views, clicks, basket information etc.) we may have more success with this content-based recommender system.\n",
    "#### On the other hand, there is a major strength to this system: by relying on only metadata features, and not using indicator features, we can recommend products which were not present when training the model. Similarly, if we have valuable user metadata we can avoid using user indicator features and make predictions for users who’ve never interacted with a product before. This is called “cold-start” recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making recommendations\n",
    "### We do this by passing the user’s feature vector and all the item features to predict_rank() and examining the resulting rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_internal 375 , para usuario 12198\n",
      "User x: Item recommendations:\n",
      "[222019, 330011, 387302, 399001, 440006, 594061, 594184, 748103, 802020, 885199]\n",
      "[106233, 146004, 198006, 320112, 448048, 625020, 647093, 845022, 865028, 950003]\n"
     ]
    }
   ],
   "source": [
    "# Pull user features out of the user features matrix and predict for just that user\n",
    "id_coppel =  12198# el cliente con mas compras en la muestra del %.01 # 18988462 # el cliente con mas compras coppel\n",
    "id_internal = idcte_to_internal_user_ids[id_coppel]\n",
    "print('id_internal {} , para usuario {}'.format(id_internal, id_coppel))\n",
    "u_features = sparse.csr_matrix(user_indicator_features)[id_internal  ] # el menos uno es importante \n",
    "u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "\n",
    "# Get internal IDs of User 432's top 10 recommendations\n",
    "# These are sorted by item ID, not by rank\n",
    "# This may contain items with which User 432 has already interacted\n",
    "k = 10\n",
    "u_top_ten_recs = numpy.where(u_rankings <= k)[0]\n",
    "u_top_ten_recs_foo = u_rankings[0:k]# yo creo que los rankings son mas bien\n",
    "print(\"User x: Item recommendations:\")\n",
    "u_top_ten_recs = [ key for key,value in idfam1_to_internal_item_ids.items() if value in u_top_ten_recs ]\n",
    "u_top_ten_recs.sort()\n",
    "u_top_ten_recs_foo = [ key for key, value in idfam1_to_internal_item_ids.items() if value in u_top_ten_recs_foo]\n",
    "u_top_ten_recs_foo.sort()\n",
    "print(u_top_ten_recs)\n",
    "print(u_top_ten_recs_foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The value of the range over which the recommender should iterate has to be the same as the # of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User0: Item recommendations:\n",
      "[ 386  505  525  844 1099 1148 1210 1823 1912 2158]\n",
      "User10000: Item recommendations:\n",
      "[  40  270  310  336  507  771 1016 1097 1440 2188]\n",
      "User20000: Item recommendations:\n",
      "[ 218  239  517 1121 1262 1611 1917 1961 2057 2284]\n",
      "User30000: Item recommendations:\n",
      "[  87  567  624  894 1039 1129 1227 1230 1914 2027]\n",
      "User40000: Item recommendations:\n",
      "[ 809  936  980 1052 1146 1282 1481 1681 2032 2169]\n",
      "User50000: Item recommendations:\n",
      "[  54  164  215  312  408 1023 1446 1607 1709 2150]\n",
      "User60000: Item recommendations:\n",
      "[  55  452 1027 1099 1105 1318 1835 1842 1955 2046]\n",
      "User70000: Item recommendations:\n",
      "[ 295  549  628  824 1035 1379 1421 1556 1662 2298]\n",
      "User80000: Item recommendations:\n",
      "[  52  200  325  351  483  572  876  885 1647 1897]\n",
      "User90000: Item recommendations:\n",
      "[  87  441  894  973 1129 1177 1946 2027 2181 2229]\n",
      "User100000: Item recommendations:\n",
      "[ 499  646  684 1281 1312 1326 1871 1947 2019 2020]\n",
      "User110000: Item recommendations:\n",
      "[ 179  210  682  732  811 1032 1107 1963 2046 2163]\n",
      "User120000: Item recommendations:\n",
      "[  48  320  456  582  708  837 1642 2045 2058 2178]\n",
      "User130000: Item recommendations:\n",
      "[ 427  442  505 1179 1214 1546 1736 1920 2008 2203]\n",
      "User140000: Item recommendations:\n",
      "[ 181  530  538  584  683  686 1272 1480 1701 1722]\n",
      "User150000: Item recommendations:\n",
      "[ 606  705 1159 1447 1560 1732 1808 1990 2132 2249]\n",
      "User160000: Item recommendations:\n",
      "[ 131  220  344  495  532 1194 1472 1694 2106 2174]\n",
      "User170000: Item recommendations:\n",
      "[ 207  288  325  572  603  876 1232 1812 1830 1991]\n",
      "User180000: Item recommendations:\n",
      "[ 110  573  791  833 1289 1332 1601 1798 1804 2200]\n",
      "User190000: Item recommendations:\n",
      "[ 263  304  612  699  834  835 1677 2123 2182 2189]\n",
      "User200000: Item recommendations:\n",
      "[ 108  110  411  808  893  898 1307 1657 1770 2181]\n",
      "User210000: Item recommendations:\n",
      "[ 161  845  917 1050 1395 1417 1544 1921 2134 2250]\n",
      "User220000: Item recommendations:\n",
      "[   2  138  835 1110 1175 1240 1439 1677 2123 2177]\n",
      "User230000: Item recommendations:\n",
      "[ 278  412  438  478  753  978 1353 1698 1850 2065]\n",
      "User240000: Item recommendations:\n",
      "[  57  235  311  667  775 1017 1174 1443 1891 2121]\n",
      "User250000: Item recommendations:\n",
      "[  14   35  278  362  412 1740 1804 1850 1954 1971]\n",
      "User260000: Item recommendations:\n",
      "[   6 1151 1174 1265 1578 1672 1921 1967 2225 2251]\n",
      "User270000: Item recommendations:\n",
      "[  87  441  567  894 1039 1129 1230 1914 2027 2181]\n",
      "User280000: Item recommendations:\n",
      "[  60  230  444  478  514 1474 1578 1624 2008 2250]\n",
      "User290000: Item recommendations:\n",
      "[  35  278  412  579  814 1353 1698 1850 1954 2112]\n",
      "User300000: Item recommendations:\n",
      "[   6  298  428  503  778 1151 1265 1317 1347 1859]\n",
      "User310000: Item recommendations:\n",
      "[  97  619  703 1617 1632 1651 1856 1973 2038 2069]\n",
      "User320000: Item recommendations:\n",
      "[ 213  405  494  506  624  668  685  766 1198 1463]\n",
      "User330000: Item recommendations:\n",
      "[ 191  312  350  526  626  681 1023 1607 1659 1661]\n",
      "User340000: Item recommendations:\n",
      "[  46  127  364  595  944 1465 1760 1766 1852 2050]\n",
      "User350000: Item recommendations:\n",
      "[ 385  573 1191 1262 1332 1423 1661 1788 1855 2284]\n",
      "User360000: Item recommendations:\n",
      "[  14  444  478 1122 1320 1624 1740 1751 2028 2151]\n",
      "User370000: Item recommendations:\n",
      "[  87  213  494  567  624 1204 1881 1914 2126 2263]\n",
      "User380000: Item recommendations:\n",
      "[  79  663  826  858  902 1152 1249 1339 1401 2291]\n",
      "User390000: Item recommendations:\n",
      "[ 228  385  517 1423 1433 1453 1574 1644 1767 1855]\n",
      "User400000: Item recommendations:\n",
      "[ 282  381  454  542  760 1044 1520 1547 1939 1957]\n",
      "User410000: Item recommendations:\n",
      "[ 121  130  367  968 1225 1456 1590 1611 1800 1961]\n",
      "User420000: Item recommendations:\n",
      "[  57  218  496  861 1391 1687 1800 1961 2057 2284]\n",
      "User430000: Item recommendations:\n",
      "[ 311  517  529  848  861 1075 1460 1596 1756 2057]\n",
      "User440000: Item recommendations:\n",
      "[ 529  861 1687 1742 1800 2010 2044 2057 2069 2251]\n",
      "User450000: Item recommendations:\n",
      "[ 191  412  427  753  908 1020 1698 1850 2065 2112]\n",
      "User460000: Item recommendations:\n",
      "[  61  446  638 1092 1659 1676 1770 1786 1796 2252]\n",
      "User470000: Item recommendations:\n",
      "[ 315  700  809 1122 1146 1235 1394 1751 1883 2169]\n",
      "User480000: Item recommendations:\n",
      "[ 191  312  350  526  573  681 1214 1661 1860 2267]\n",
      "User490000: Item recommendations:\n",
      "[  32  229  230  496 1017 1174 1391 1456 1721 2284]\n",
      "User500000: Item recommendations:\n",
      "[  61  340  866  898 1020 1303 1354 1657 1659 2050]\n",
      "User510000: Item recommendations:\n",
      "[ 105  551  786 1012 1313 1426 1576 1771 1865 2161]\n",
      "User520000: Item recommendations:\n",
      "[ 833  881  936 1122 1282 1361 1681 1751 1883 2032]\n",
      "User530000: Item recommendations:\n",
      "[ 205  506  766  896 1115 1271 1305 1463 1635 2059]\n",
      "User540000: Item recommendations:\n",
      "[ 108  110  441  808  980 1052 1458 1629 2032 2073]\n",
      "User550000: Item recommendations:\n",
      "[  96  174 1029 1123 1184 1190 1452 2108 2237 2273]\n",
      "User560000: Item recommendations:\n",
      "[ 362  529  861 1391 1460 1967 2010 2057 2069 2251]\n"
     ]
    }
   ],
   "source": [
    "# Pull user features out of the user features matrix and predict for just all users\n",
    "for user in range(0, n_users, 10000):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    print(\"User\"+str(user)+\": Item recommendations:\")\n",
    "    print(u_top_ten_recs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Internal IDs back to the original IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 10002: Item recommendations:\n",
      "301020\n",
      "774255\n",
      "775257\n",
      "326113\n",
      "844020\n",
      "245010\n",
      "701065\n",
      "381004\n",
      "305145\n",
      "210003\n",
      "User 10006: Item recommendations:\n",
      "874198\n",
      "202014\n",
      "210029\n",
      "316019\n",
      "596061\n",
      "295030\n",
      "310121\n",
      "965002\n",
      "582010\n",
      "501009\n",
      "User 10011: Item recommendations:\n",
      "418073\n",
      "491005\n",
      "646266\n",
      "380535\n",
      "456040\n",
      "990001\n",
      "739104\n",
      "194085\n",
      "501018\n",
      "266004\n",
      "User 10036: Item recommendations:\n",
      "423073\n",
      "301002\n",
      "295028\n",
      "307479\n",
      "308012\n",
      "807027\n",
      "405004\n",
      "210090\n",
      "399099\n",
      "415015\n",
      "User 10039: Item recommendations:\n",
      "541079\n",
      "515025\n",
      "403279\n",
      "302004\n",
      "244075\n",
      "808002\n",
      "488007\n",
      "334034\n",
      "532035\n",
      "352002\n"
     ]
    }
   ],
   "source": [
    "for user in range(5):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    print(\"User \"+str(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)])+\": Item recommendations:\")\n",
    "    #print(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)]) \n",
    "    for m in u_top_ten_recs:\n",
    "        print(list(idfam1_to_internal_item_ids.keys())[list(idfam1_to_internal_item_ids.values()).index(m)]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and writing a resulting CSV for recommendations for all users in the input database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443.5133612155914\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "HybridRecommendations=pd.DataFrame([])\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for user in range(n_users):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    if user %100 ==0 :\n",
    "        print(user)\n",
    "    user_id =str(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)])\n",
    "    for m in u_top_ten_recs:\n",
    "        items = (list(idfam1_to_internal_item_ids.keys())[list(idfam1_to_internal_item_ids.values()).index(m)]) \n",
    "        HybridRecommendations=HybridRecommendations.append(pd.DataFrame({'itemId': items,'userId': user_id}, index=[0]), ignore_index=True)\n",
    "t2 = time.time()\n",
    "total = t2-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:37, 37.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521.4517896175385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t2 = time.time()\n",
    "idfam1_to_internal_item_ids_REVERSE = {}\n",
    "for key, value in idfam1_to_internal_item_ids.items():\n",
    "    idfam1_to_internal_item_ids_REVERSE[value] = key\n",
    "k = 10\n",
    "\n",
    "from numpy import *\n",
    "u_features = sparse.csr_matrix(full_user_features)\n",
    "u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)\n",
    "    \n",
    "result = [list(flatnonzero(row  <= k)) for row in u_rankings]\n",
    "result = numpy.matrix(result)\n",
    "result = pd.DataFrame(result, columns=[ 'item' + str( i+1) for i in range(k)] )\n",
    "result['userId'] = idcte_to_internal_user_ids.keys()\n",
    "result = pd.melt(result, id_vars=['userId'], value_vars=[ 'item' + str( i+1) for i in range(k)])\n",
    "del result['variable']\n",
    "result = result.rename(columns={\"value\": \"itemId\"})\n",
    "result['itemId'] = result['itemId'].apply( lambda x: idfam1_to_internal_item_ids_REVERSE[x])\n",
    "result\n",
    "table_id = 'Resultados.test_tensorrec_03_porciento_17_junio_2020'\n",
    "result.to_gbq(table_id, project_id='rmf2gcp')\n",
    "t3 = time.time()\n",
    "total = t3-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>301020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006</td>\n",
       "      <td>874198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10011</td>\n",
       "      <td>418073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10036</td>\n",
       "      <td>423073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10039</td>\n",
       "      <td>541079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId\n",
       "0   10002  301020\n",
       "1   10006  874198\n",
       "2   10011  418073\n",
       "3   10036  423073\n",
       "4   10039  541079"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Recommender can also be used to predict similar items given some item IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 0.99999994),\n",
       "  (383, 0.94644976),\n",
       "  (810, 0.9398602),\n",
       "  (838, 0.93781996),\n",
       "  (965, 0.93415636),\n",
       "  (2261, 0.9293994),\n",
       "  (940, 0.92884135),\n",
       "  (2133, 0.92827964),\n",
       "  (1428, 0.92538106),\n",
       "  (1706, 0.92044765)],\n",
       " [(55, 0.99999976),\n",
       "  (1955, 0.98327947),\n",
       "  (1442, 0.98308074),\n",
       "  (991, 0.9588507),\n",
       "  (1119, 0.956786),\n",
       "  (597, 0.94848186),\n",
       "  (1790, 0.9456929),\n",
       "  (1835, 0.9435216),\n",
       "  (680, 0.9406038),\n",
       "  (1729, 0.9363351)],\n",
       " [(90, 0.9999999),\n",
       "  (405, 0.97637963),\n",
       "  (1818, 0.9741595),\n",
       "  (1107, 0.95932835),\n",
       "  (1102, 0.95911574),\n",
       "  (682, 0.9570637),\n",
       "  (1963, 0.9511348),\n",
       "  (654, 0.94249254),\n",
       "  (398, 0.9391309),\n",
       "  (1473, 0.938779)]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model.predict_similar_items(item_features=item_indicator_features,item_ids=[3,55,90], n_similar=10) #sera util para los usuarios de compra en efectivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695710, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
