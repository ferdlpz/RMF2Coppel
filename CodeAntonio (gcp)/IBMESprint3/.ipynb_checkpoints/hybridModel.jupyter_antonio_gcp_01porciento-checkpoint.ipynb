{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRec recommender engine:\n",
    "## Prototyping of a recommender system in Python using TensorRec including input data manipulation, algorithm design, and usage for prediction.\n",
    "\n",
    "#### TensorRec is a Python package for building recommender systems. A TensorRec recommender system consumes three pieces of input data: user features, item features, and interactions. Based on the user/item features, the system will predict which items to recommend. The interactions are used when fitting the model: predictions are compared to the interactions and a loss/penalty is calculated, which the system learns to decrease. As we prototype our system, we tackle three major situations: how we handle interactions, how we handle features, and how we structure the recommender itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*YotDpHjvGL8xK91ZggthbA.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/getting-started-with-recommender-systems-and-tensorrec-8f50a9943eef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw ratings load :Each row represents a single rating: one user and one item. We’ll be using these ratings(frequency of purchase of each item) as our interactions between the user and the product."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import six\n",
    "print(six.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!pip install --upgrade six==1.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import time\n",
    "t0 = time.time()\n",
    "limite = 189857 # 18,985,770  # corre en mi local %0.1 del total de la muestra\n",
    "\n",
    "# functions\n",
    "def get_data_BQ(sql):\n",
    "    client = bigquery.Client()\n",
    "    df = client.query(sql).to_dataframe()\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\n",
      "FROM `rmf2gcp.RawData.Workflow_aggregado`\n",
      "WHERE id_table_dem <=  189857 ORDER BY USERID\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10002, 229008, 1],\n",
       " [10002, 222011, 1],\n",
       " [10002, 210070, 1],\n",
       " [10002, 869007, 4],\n",
       " [10002, 124002, 1],\n",
       " [10002, 665040, 1],\n",
       " [10002, 219060, 1]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql =  '''SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\n",
    "FROM `rmf2gcp.RawData.Workflow_aggregado`\n",
    "WHERE id_table_dem <=  ''' + str(limite) + ''' ORDER BY USERID'''\n",
    "\n",
    "print(sql)\n",
    "raw_ratings = get_data_BQ(sql)\n",
    "raw_ratings = raw_ratings.values.tolist() # pues vamos a seguir su mala practica de hacer una lista de listas \n",
    "raw_ratings[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the input to map Item and User IDs to new internal IDs\n",
    "### The new internal IDs will be created by the defaultdict on insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189857\n",
      "2218\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "idcte_to_internal_user_ids = collections.defaultdict(lambda: len(idcte_to_internal_user_ids))\n",
    "idfam1_to_internal_item_ids = collections.defaultdict(lambda: len(idfam1_to_internal_item_ids))\n",
    "for row in raw_ratings:\n",
    "    row[0] = idcte_to_internal_user_ids[int(row[0])]\n",
    "    row[1] = idfam1_to_internal_item_ids[int(row[1])]\n",
    "    row[2] = float(row[2])    # esta operacion esta de más \n",
    "n_users = len(idcte_to_internal_user_ids)\n",
    "n_items = len(idfam1_to_internal_item_ids)\n",
    "print(n_users)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(229008, 0), (222011, 1), (210070, 2), (869007, 3), (124002, 4), (665040, 5), (219060, 6)]\n",
      "[(10002, 0), (10006, 1), (10011, 2), (10036, 3), (10039, 4), (10043, 5), (10047, 6)]\n"
     ]
    }
   ],
   "source": [
    "print( [ (key, value) for key, value  in idfam1_to_internal_item_ids.items() ][0:7])\n",
    "print( [ (key, value) for key, value  in idcte_to_internal_user_ids.items() ][0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import numpy \n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, we’ll break the ratings in to a training and test set by shuffling and splitting the ratings. Our prototypes will be trained on the training set, and we’ll evaluate their success using the test set. Splitting the train/test sets at random like this is crude, and there are more rigorous techniques for model evaluation, but it is quick and clear for the purposes of this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the ratings and split them in to train/test sets 80%/20%\n",
    "random.shuffle(raw_ratings)  # Shuffles the list in-place\n",
    "cutoff = int(.8 * len(raw_ratings))\n",
    "train_ratings = raw_ratings[:cutoff]\n",
    "test_ratings = raw_ratings[cutoff:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we reorganize these ratings in to a Scipy sparse matrix. In this matrix, every row represents a user and every column is an item. The [i, j]th value in this matrix is User i’s interaction with Item j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This method converts a list of (user, item, rating) to a sparse matrix\n",
    "def interactions_list_to_sparse_matrix(interactions):\n",
    "    users_column, items_column, ratings_column, = zip(*interactions)\n",
    "    return sparse.coo_matrix((ratings_column, (users_column, items_column)),\n",
    "                             shape=(n_users, n_items))\n",
    "\n",
    "\n",
    "# Create sparse matrices of interaction data\n",
    "sparse_train_ratings = interactions_list_to_sparse_matrix(raw_ratings)\n",
    "sparse_test_ratings = interactions_list_to_sparse_matrix(test_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<189857x2218 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3817915 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_train_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRec library runs on TensorFlow so we install a compatible version of TensorFlow \n",
    "### Both TensorFlow and TensorRec can be installed using !pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189857\n"
     ]
    }
   ],
   "source": [
    "#!pip install \"tensorflow==1.13.1\"\n",
    "print(n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.3-dlenv_tfe\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorrec --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter Prototype\n",
    "### A collaborative filter is an algorithm that learns which users have similar tastes and recommends items to a user based on what similar users have liked. A common way to do this is through matrix factorization. In matrix factorization, we have to learn two matrices (user representations and item representations) that, when multiplied together, approximate the interactions:\n",
    "#### TensorRec will perform matrix factorization by default if it is given only identity matrices as user/item features. These identity matrices are often called “indicator features.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training collaborative filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Construct indicator features for users and items\n",
    "user_indicator_features = sparse.identity(n_users)\n",
    "item_indicator_features = sparse.identity(n_items)\n",
    "\n",
    "# Build a matrix factorization collaborative filter model\n",
    "cf_model = tensorrec.TensorRec(n_components=5)\n",
    "\n",
    "# Fit the collaborative filter model\n",
    "print(\"Training collaborative filter\")\n",
    "cf_model.fit(interactions=sparse_train_ratings,\n",
    "             user_features=user_indicator_features,\n",
    "             item_features=item_indicator_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Graphs\n",
    "### One way we can configure our TensorRec system is by changing the loss graph. The loss graph takes in predictions and interactions and calculates a penalty (loss) that the system will try to decrease as it learns.\n",
    "#### WMRB, which stands for “weighted margin-rank batch,” works by taking a random sample of items the user hasn’t interacted with and comparing their predictions to items the user likes. Over time, this pushes items a user likes to the top of the rankings. We can try using different loss graphs like WARP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Let's try a new loss function: WMRB \n",
    "'''\n",
    "print(\"Training collaborative filter with WMRB loss\")\n",
    "ranking_cf_model = tensorrec.TensorRec(n_components=5,\n",
    "                                       loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "ranking_cf_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                     user_features=user_indicator_features,\n",
    "                     item_features=item_indicator_features,\n",
    "                     n_sampled_items=int(n_items *1))\n",
    "\n",
    "# Check the results of the WMRB MF CF model\n",
    "print(\"WMRB matrix factorization collaborative filter:\")\n",
    "predicted_ranks = ranking_cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                                item_features=item_indicator_features)\n",
    "                                                '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Metadata Features\n",
    "## To continue experimenting, we should try to make use of other data available to us. We will try using User Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT USERID, FEATURES, STATE\n",
      "FROM `rmf2gcp.RawData.demographics_features` \n",
      "WHERE id_table_dem <= 189857\n"
     ]
    }
   ],
   "source": [
    "# To improve the recommendations, lets read in the user demographic data\n",
    "sql = \"\"\"\n",
    "SELECT USERID, FEATURES, STATE\n",
    "FROM `rmf2gcp.RawData.demographics_features` \n",
    "WHERE id_table_dem <= \"\"\" + str(limite)\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     USERID FEATURES                      STATE\n",
      "0     10006   81,C,M  SINALOA                  \n",
      "1     10059   87,C,M  SINALOA                  \n",
      "2     10110   88,V,M  SINALOA                  \n",
      "3     10118   89,S,F  SINALOA                  \n",
      "4     10130   83,V,F  SINALOA                  \n",
      "..      ...      ...                        ...\n",
      "795   22555   87,C,F  SINALOA                  \n",
      "796   22580   84,C,F  SINALOA                  \n",
      "797   22589   61,S,F  SINALOA                  \n",
      "798   22624   86,C,M  SINALOA                  \n",
      "799   22629   71,V,F  SINALOA                  \n",
      "\n",
      "[800 rows x 3 columns]\n",
      "USERID       int64\n",
      "FEATURES    object\n",
      "STATE       object\n",
      "dtype: object\n",
      "Index(['USERID', 'FEATURES', 'STATE'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['USERID', 'FEATURES', 'STATE']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_user_metadata = get_data_BQ(sql)\n",
    "print(raw_user_metadata.head(800))\n",
    "print(raw_user_metadata.dtypes)\n",
    "print(raw_user_metadata.columns)\n",
    "raw_user_metadata_header = ['USERID', 'FEATURES', 'STATE']\n",
    "raw_user_metadata_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10006, '81,C,M', 'SINALOA                  '],\n",
       " [10059, '87,C,M', 'SINALOA                  '],\n",
       " [10110, '88,V,M', 'SINALOA                  '],\n",
       " [10118, '89,S,F', 'SINALOA                  '],\n",
       " [10130, '83,V,F', 'SINALOA                  '],\n",
       " [10135, '79,C,F', 'SINALOA                  '],\n",
       " [10192, '71,S,M', 'SINALOA                  ']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_user_metadata = raw_user_metadata.values.tolist()\n",
    "raw_user_metadata[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we’ll want to read this data, map the movies to our internal IDs, and keep track of the features for each user. Then we’ll binarize the feature  labels using Scikit’s MultiLabelBinarizer. The binarized output will be our features for our new recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw metadata example:\n",
      "['USERID', 'FEATURES', 'STATE']\n",
      "[2218, ['81', 'C', 'M'], 'SINALOA                  ']\n"
     ]
    }
   ],
   "source": [
    "# Map the features IDs to our internal IDs and keep track of the gender and age\n",
    "temp_string = ''\n",
    "temp_list = []\n",
    "count = 1\n",
    "user_id_by_internal_id = {}\n",
    "user_features_by_internal_id = {}\n",
    "for row in raw_user_metadata:\n",
    "    temp_string = ''\n",
    "    temp_list = []\n",
    "    \n",
    "\n",
    "    temp_string = str(row[0])\n",
    "    temp_list = row[1].split(',')\n",
    "    #print(count)\n",
    "    #print(temp_string)\n",
    "    #print(temp_list)\n",
    "    row[0] = idfam1_to_internal_item_ids[int(temp_string)]  # Map to IDs\n",
    "    row[1] = temp_list  # Split up\n",
    "    user_id_by_internal_id[temp_string] = temp_string\n",
    "    user_features_by_internal_id[int(temp_string)] = row[1]\n",
    "    count+=1\n",
    "# Look at an example user metadata row\n",
    "print(\"Raw metadata example:\\n{}\\n{}\".format(raw_user_metadata_header, \n",
    "                                             raw_user_metadata[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10006, ['81', 'C', 'M']),\n",
       " (10059, ['87', 'C', 'M']),\n",
       " (10110, ['88', 'V', 'M']),\n",
       " (10118, ['89', 'S', 'F']),\n",
       " (10130, ['83', 'V', 'F']),\n",
       " (10135, ['79', 'C', 'F']),\n",
       " (10192, ['71', 'S', 'M'])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (key, value) for key,value in user_features_by_internal_id.items() ][0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a list of features where the index is the internal user ID and the value is a list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = [user_features_by_internal_id[internal_id]\n",
    "                for internal_id in user_features_by_internal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['81', 'C', 'M'],\n",
       " ['87', 'C', 'M'],\n",
       " ['88', 'V', 'M'],\n",
       " ['89', 'S', 'F'],\n",
       " ['83', 'V', 'F'],\n",
       " ['79', 'C', 'F'],\n",
       " ['71', 'S', 'M']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "29 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the features into binarized labels using scikit's MultiLabelBinarizer\n",
    "user_features = MultiLabelBinarizer().fit_transform(user_feat)\n",
    "n_features = user_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 #perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coerce the user features to a sparse matrix, which TensorRec expects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<189857x95 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 569571 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_mat = sparse.coo_matrix(user_features)\n",
    "user_features_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s not as good as the ranking collaborative filter but it’s significantly more effective if we add it to the base collaborative filter.\n",
    "#### There is a major weakness to this system: user feature alone are not very descriptive and are not enough information to make an informed recommendation. If we had more descriptive metadata and item metadata (views, clicks, basket information etc.) we may have more success with this content-based recommender system.\n",
    "#### On the other hand, there is a major strength to this system: by relying on only metadata features, and not using indicator features, we can recommend products which were not present when training the model. Similarly, if we have valuable user metadata we can avoid using user indicator features and make predictions for users who’ve never interacted with a product before. This is called “cold-start” recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid recommender: \n",
    "## Hybrid recommender systems combine two or more recommendation strategies in different ways to benefit from their complementary advantages.\n",
    "### Let’s combine these two: we’ll use indicator features to get the strengths of a collaborative filter, and we’ll also use the content features to take advantage of the metadata. This combination of collaborative filtering and content-based recommendation is the hybrid model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do this by stacking the two sets of features together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<189857x189952 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 759428 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try concatenating the user features on to the indicator features for a hybrid recommender system\n",
    "full_user_features = sparse.hstack([user_indicator_features, user_features_mat])\n",
    "full_user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:n_sampled_items was specified, but the loss graph is not sample-based\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hybrid recommender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Training hybrid recommender\")\n",
    "hybrid_model = tensorrec.TensorRec(\n",
    "    n_components=5\n",
    ")\n",
    "hybrid_model.fit(interactions=sparse_train_ratings,\n",
    "                 user_features=full_user_features,\n",
    "                 item_features=item_indicator_features,\n",
    "                 n_sampled_items=int(n_items * .01))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This performs the best even though we are using trivial features from users. If we have more metadata, we can expect larger impact of the Hybrid recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid recommender:\n",
      "Performance metrics: Train: 0.0242 Test: 0.0263\n"
     ]
    }
   ],
   "source": [
    "print(\"Hybrid recommender:\")\n",
    "predicted_ranks = hybrid_model.predict_rank(user_features=full_user_features,\n",
    "                                            item_features=item_indicator_features)\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Performance metrics: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the model: first prototype\n",
    "#### To do this, we’ll look at a metric called “recall at K.” Recall@K says, for the average user, what percentage of their test items made it in to the top K in the predicted rankings.\n",
    "#### Recall@K is a nice metric for many recommender systems because it emulates the behavior of a recommendation product. Before calculating the recall, we’ll want to decide which interactions should count as a “purchased item.” In this case, choose to use all ratings of at least 1.0 as “liked products” and ignore the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factorization collaborative filter:\n",
      "Performance metrics: Train: 0.0045 Test: 0.0047\n"
     ]
    }
   ],
   "source": [
    "# Create sets of train/test interactions that are only frequency > 1 since these represent the products that have been purchased \n",
    "sparse_train_ratings_1plus = sparse_train_ratings.multiply(sparse_train_ratings >= 1)\n",
    "sparse_test_ratings_1plus = sparse_test_ratings.multiply(sparse_test_ratings >= 1)\n",
    "\n",
    "\n",
    "# This method consumes item ranks for each user and prints out train/test metrics\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Performance metrics: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "\n",
    "# Check the results of the MF CF model\n",
    "print(\"Matrix factorization collaborative filter:\")\n",
    "predicted_ranks = cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                        item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "38 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "39 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43 #perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Recommendation\n",
    "### Now that we have metadata about our user, one thing we can try is to recommend based solely on the user metadata.\n",
    "### To do this, we will configure a TensorRec model to use a pass-through representation graph for item features. For us, this means that the user representations will be the same as the user features that are passed in (just the user information like gender, age etc.) and the item representations will reflect how much the item suits that particular set of user features.\n",
    "#### Ideal case is when we would have item metadata as well: because that would have a greater impact on making the recommendation better- also help solving the cold start problem. There is a major weakness to this system: these features alone are not very descriptive and are not enough information to make an informed recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training content-based recommender\n"
     ]
    }
   ],
   "source": [
    "# Fit a content-based model using the user features\n",
    "print(\"Training content-based recommender\")\n",
    "content_model = tensorrec.TensorRec(\n",
    "    n_components=n_features,\n",
    "   user_repr_graph=tensorrec.representation_graphs.FeaturePassThroughRepresentationGraph()\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:n_sampled_items was specified, but the loss graph is not sample-based\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "content_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                  user_features=user_features_mat,\n",
    "                  item_features=item_indicator_features,\n",
    "                  n_sampled_items=int(n_items * .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-based recommender:\n",
      "Performance metrics: Train: 0.0276 Test: 0.0298\n"
     ]
    }
   ],
   "source": [
    "# Check the results of the content-based model\n",
    "print(\"Content-based recommender:\")\n",
    "predicted_ranks = content_model.predict_rank(user_features=user_features_mat,\n",
    "                                             item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48 # perdido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49 # perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s not as good as the ranking collaborative filter but it’s significantly more effective if we add it to the base collaborative filter.\n",
    "#### There is a major weakness to this system: user feature alone are not very descriptive and are not enough information to make an informed recommendation. If we had more descriptive metadata and item metadata (views, clicks, basket information etc.) we may have more success with this content-based recommender system.\n",
    "#### On the other hand, there is a major strength to this system: by relying on only metadata features, and not using indicator features, we can recommend products which were not present when training the model. Similarly, if we have valuable user metadata we can avoid using user indicator features and make predictions for users who’ve never interacted with a product before. This is called “cold-start” recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making recommendations\n",
    "### We do this by passing the user’s feature vector and all the item features to predict_rank() and examining the resulting rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_internal 375 , para usuario 12198\n",
      "User x: Item recommendations:\n",
      "[106060, 184005, 209031, 223020, 303004, 532015, 536006, 540023, 620040, 665045]\n",
      "[104118, 293001, 299001, 401324, 410070, 415005, 454010, 739105, 901001, 910004]\n"
     ]
    }
   ],
   "source": [
    "# Pull user features out of the user features matrix and predict for just that user\n",
    "id_coppel =  12198# el cliente con mas compras en la muestra del %.01 # 18988462 # el cliente con mas compras coppel\n",
    "id_internal = idcte_to_internal_user_ids[id_coppel]\n",
    "print('id_internal {} , para usuario {}'.format(id_internal, id_coppel))\n",
    "u_features = sparse.csr_matrix(user_indicator_features)[id_internal  ] # el menos uno es importante \n",
    "u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "\n",
    "# Get internal IDs of User 432's top 10 recommendations\n",
    "# These are sorted by item ID, not by rank\n",
    "# This may contain items with which User 432 has already interacted\n",
    "k = 10\n",
    "u_top_ten_recs = numpy.where(u_rankings <= k)[0]\n",
    "u_top_ten_recs_foo = u_rankings[0:k]# yo creo que los rankings son mas bien\n",
    "print(\"User x: Item recommendations:\")\n",
    "u_top_ten_recs = [ key for key,value in idfam1_to_internal_item_ids.items() if value in u_top_ten_recs ]\n",
    "u_top_ten_recs.sort()\n",
    "u_top_ten_recs_foo = [ key for key, value in idfam1_to_internal_item_ids.items() if value in u_top_ten_recs_foo]\n",
    "u_top_ten_recs_foo.sort()\n",
    "print(u_top_ten_recs)\n",
    "print(u_top_ten_recs_foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The value of the range over which the recommender should iterate has to be the same as the # of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User0: Item recommendations:\n",
      "[ 724  892 1143 1275 1530 1563 1676 1963 1986 2213]\n",
      "User10000: Item recommendations:\n",
      "[ 162  251  263  281  625  805  858 1041 1108 2028]\n",
      "User20000: Item recommendations:\n",
      "[ 177  406  407  959 1091 1122 1392 1561 1642 2138]\n",
      "User30000: Item recommendations:\n",
      "[  32  498  667  811  940 1331 1333 1343 1667 1960]\n",
      "User40000: Item recommendations:\n",
      "[ 114  308  504  622  724  740  830 1625 1663 1704]\n",
      "User50000: Item recommendations:\n",
      "[  47  262  286  511 1165 1365 1457 1648 1895 1905]\n",
      "User60000: Item recommendations:\n",
      "[ 284  697 1060 1077 1134 1350 1603 1977 2006 2087]\n",
      "User70000: Item recommendations:\n",
      "[  47  286  594  831 1060 1365 1521 1612 1648 1895]\n",
      "User80000: Item recommendations:\n",
      "[ 495  594  623  697  807 1134 1583 1787 1977 2044]\n",
      "User90000: Item recommendations:\n",
      "[ 286  511  594  806 1060 1223 1421 1521 1828 1914]\n",
      "User100000: Item recommendations:\n",
      "[ 325  358  628  645  770  790  948 1201 1336 1965]\n",
      "User110000: Item recommendations:\n",
      "[ 134  417  423  922 1445 1462 1514 1555 1770 2163]\n",
      "User120000: Item recommendations:\n",
      "[ 200  262  459  850 1458 1648 1895 1905 1913 2125]\n",
      "User130000: Item recommendations:\n",
      "[  88  234 1133 1158 1306 1393 1511 1533 1981 2016]\n",
      "User140000: Item recommendations:\n",
      "[ 358  739  831 1060 1077 1093 1421 1612 1750 1780]\n",
      "User150000: Item recommendations:\n",
      "[ 260  358  739 1077 1134 1141 1279 1551 1780 1828]\n",
      "User160000: Item recommendations:\n",
      "[ 371  434  458 1168 1170 1282 1286 1743 1881 2015]\n",
      "User170000: Item recommendations:\n",
      "[ 147  332  455  621  805 1671 1845 2109 2132 2172]\n",
      "User180000: Item recommendations:\n",
      "[ 495  623  807 1248 1278 1583 1787 2044 2056 2212]\n"
     ]
    }
   ],
   "source": [
    "# Pull user features out of the user features matrix and predict for just all users\n",
    "for user in range(0, n_users, 10000):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    print(\"User\"+str(user)+\": Item recommendations:\")\n",
    "    print(u_top_ten_recs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Internal IDs back to the original IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 10002: Item recommendations:\n",
      "295025\n",
      "252020\n",
      "707373\n",
      "930001\n",
      "328010\n",
      "535020\n",
      "530015\n",
      "750483\n",
      "440010\n",
      "217001\n",
      "User 10006: Item recommendations:\n",
      "380284\n",
      "103087\n",
      "585375\n",
      "898009\n",
      "106236\n",
      "243030\n",
      "508030\n",
      "699001\n",
      "901003\n",
      "292005\n",
      "User 10011: Item recommendations:\n",
      "541036\n",
      "586032\n",
      "705357\n",
      "537078\n",
      "680010\n",
      "466002\n",
      "338010\n",
      "542033\n",
      "136005\n",
      "295024\n",
      "User 10036: Item recommendations:\n",
      "995003\n",
      "544005\n",
      "665025\n",
      "202020\n",
      "647093\n",
      "459015\n",
      "845022\n",
      "112343\n",
      "501011\n",
      "295018\n",
      "User 10039: Item recommendations:\n",
      "867049\n",
      "594089\n",
      "210075\n",
      "520004\n",
      "805003\n",
      "410223\n",
      "509010\n",
      "826001\n",
      "295020\n",
      "307476\n"
     ]
    }
   ],
   "source": [
    "for user in range(5):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    print(\"User \"+str(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)])+\": Item recommendations:\")\n",
    "    #print(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)]) \n",
    "    for m in u_top_ten_recs:\n",
    "        print(list(idfam1_to_internal_item_ids.keys())[list(idfam1_to_internal_item_ids.values()).index(m)]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and writing a resulting CSV for recommendations for all users in the input database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.1249258518219\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "HybridRecommendations=pd.DataFrame([])\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for user in range(n_users):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    if user %100 ==0 :\n",
    "        print(user)\n",
    "    user_id =str(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)])\n",
    "    for m in u_top_ten_recs:\n",
    "        items = (list(idfam1_to_internal_item_ids.keys())[list(idfam1_to_internal_item_ids.values()).index(m)]) \n",
    "        HybridRecommendations=HybridRecommendations.append(pd.DataFrame({'itemId': items,'userId': user_id}, index=[0]), ignore_index=True)\n",
    "t2 = time.time()\n",
    "total = t2-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:18, 18.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532.1471707820892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t2 = time.time()\n",
    "idfam1_to_internal_item_ids_REVERSE = {}\n",
    "for key, value in idfam1_to_internal_item_ids.items():\n",
    "    idfam1_to_internal_item_ids_REVERSE[value] = key\n",
    "k = 10\n",
    "\n",
    "from numpy import *\n",
    "u_features = sparse.csr_matrix(full_user_features)\n",
    "u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)\n",
    "    \n",
    "result = [list(flatnonzero(row  <= k)) for row in u_rankings]\n",
    "result = numpy.matrix(result)\n",
    "result = pd.DataFrame(result, columns=[ 'item' + str( i+1) for i in range(k)] )\n",
    "result['userId'] = idcte_to_internal_user_ids.keys()\n",
    "result = pd.melt(result, id_vars=['userId'], value_vars=[ 'item' + str( i+1) for i in range(k)])\n",
    "del result['variable']\n",
    "result = result.rename(columns={\"value\": \"itemId\"})\n",
    "result['itemId'] = result['itemId'].apply( lambda x: idfam1_to_internal_item_ids_REVERSE[x])\n",
    "result\n",
    "table_id = 'Resultados.test_tensorrec_1porciento_17_junio_2020'\n",
    "result.to_gbq(table_id, project_id='rmf2gcp')\n",
    "t3 = time.time()\n",
    "total = t3-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>295025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006</td>\n",
       "      <td>380284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10011</td>\n",
       "      <td>541036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10036</td>\n",
       "      <td>995003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10039</td>\n",
       "      <td>867049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId\n",
       "0   10002  295025\n",
       "1   10006  380284\n",
       "2   10011  541036\n",
       "3   10036  995003\n",
       "4   10039  867049"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Recommender can also be used to predict similar items given some item IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 0.99999994),\n",
       "  (201, 0.96030784),\n",
       "  (1218, 0.9601003),\n",
       "  (413, 0.95659),\n",
       "  (1830, 0.9485041),\n",
       "  (573, 0.9404923),\n",
       "  (898, 0.940253),\n",
       "  (944, 0.93837),\n",
       "  (478, 0.933781),\n",
       "  (571, 0.928842)],\n",
       " [(55, 0.99999994),\n",
       "  (184, 0.97645694),\n",
       "  (1617, 0.9759781),\n",
       "  (54, 0.97468394),\n",
       "  (1005, 0.9693477),\n",
       "  (812, 0.9650873),\n",
       "  (213, 0.95942044),\n",
       "  (1074, 0.9519307),\n",
       "  (492, 0.9482232),\n",
       "  (101, 0.94792134)],\n",
       " [(90, 1.0),\n",
       "  (2134, 0.99125034),\n",
       "  (604, 0.9564189),\n",
       "  (115, 0.9538647),\n",
       "  (391, 0.9427095),\n",
       "  (23, 0.940056),\n",
       "  (1413, 0.9284144),\n",
       "  (688, 0.92514735),\n",
       "  (1100, 0.9208642),\n",
       "  (1894, 0.9184559)]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model.predict_similar_items(item_features=item_indicator_features,item_ids=[3,55,90], n_similar=10) #sera util para los usuarios de compra en efectivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1898570, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
