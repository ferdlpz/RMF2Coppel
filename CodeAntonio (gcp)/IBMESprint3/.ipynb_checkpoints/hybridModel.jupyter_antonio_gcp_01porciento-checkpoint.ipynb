{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRec recommender engine:\n",
    "## Prototyping of a recommender system in Python using TensorRec including input data manipulation, algorithm design, and usage for prediction.\n",
    "\n",
    "#### TensorRec is a Python package for building recommender systems. A TensorRec recommender system consumes three pieces of input data: user features, item features, and interactions. Based on the user/item features, the system will predict which items to recommend. The interactions are used when fitting the model: predictions are compared to the interactions and a loss/penalty is calculated, which the system learns to decrease. As we prototype our system, we tackle three major situations: how we handle interactions, how we handle features, and how we structure the recommender itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*YotDpHjvGL8xK91ZggthbA.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/getting-started-with-recommender-systems-and-tensorrec-8f50a9943eef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw ratings load :Each row represents a single rating: one user and one item. We’ll be using these ratings(frequency of purchase of each item) as our interactions between the user and the product."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import six\n",
    "print(six.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!pip install --upgrade six==1.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import time\n",
    "t0 = time.time()\n",
    "limite = 189857 # 18,985,770  # corre en mi local %0.1 del total de la muestra\n",
    "\n",
    "# functions\n",
    "def get_data_BQ(sql):\n",
    "    client = bigquery.Client()\n",
    "    df = client.query(sql).to_dataframe()\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql =  '''SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\n",
    "FROM `rmf2gcp.RawData.Workflow_aggregado`\n",
    "WHERE id_table_dem <=  ''' + str(limite) + ''' ORDER BY USERID'''\n",
    "\n",
    "print(sql)\n",
    "raw_ratings = get_data_BQ(sql)\n",
    "raw_ratings = raw_ratings.values.tolist() # pues vamos a seguir su mala practica de hacer una lista de listas \n",
    "raw_ratings[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the input to map Item and User IDs to new internal IDs\n",
    "### The new internal IDs will be created by the defaultdict on insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "idcte_to_internal_user_ids = collections.defaultdict(lambda: len(idcte_to_internal_user_ids))\n",
    "idfam1_to_internal_item_ids = collections.defaultdict(lambda: len(idfam1_to_internal_item_ids))\n",
    "for row in raw_ratings:\n",
    "    row[0] = idcte_to_internal_user_ids[int(row[0])]\n",
    "    row[1] = idfam1_to_internal_item_ids[int(row[1])]\n",
    "    row[2] = float(row[2])    # esta operacion esta de más \n",
    "n_users = len(idcte_to_internal_user_ids)\n",
    "n_items = len(idfam1_to_internal_item_ids)\n",
    "print(n_users)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( [ (key, value) for key, value  in idfam1_to_internal_item_ids.items() ][0:7])\n",
    "print( [ (key, value) for key, value  in idcte_to_internal_user_ids.items() ][0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import numpy \n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, we’ll break the ratings in to a training and test set by shuffling and splitting the ratings. Our prototypes will be trained on the training set, and we’ll evaluate their success using the test set. Splitting the train/test sets at random like this is crude, and there are more rigorous techniques for model evaluation, but it is quick and clear for the purposes of this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the ratings and split them in to train/test sets 80%/20%\n",
    "random.shuffle(raw_ratings)  # Shuffles the list in-place\n",
    "cutoff = int(.8 * len(raw_ratings))\n",
    "train_ratings = raw_ratings[:cutoff]\n",
    "test_ratings = raw_ratings[cutoff:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we reorganize these ratings in to a Scipy sparse matrix. In this matrix, every row represents a user and every column is an item. The [i, j]th value in this matrix is User i’s interaction with Item j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This method converts a list of (user, item, rating) to a sparse matrix\n",
    "def interactions_list_to_sparse_matrix(interactions):\n",
    "    users_column, items_column, ratings_column, = zip(*interactions)\n",
    "    return sparse.coo_matrix((ratings_column, (users_column, items_column)),\n",
    "                             shape=(n_users, n_items))\n",
    "\n",
    "\n",
    "# Create sparse matrices of interaction data\n",
    "sparse_train_ratings = interactions_list_to_sparse_matrix(raw_ratings)\n",
    "sparse_test_ratings = interactions_list_to_sparse_matrix(test_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_train_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRec library runs on TensorFlow so we install a compatible version of TensorFlow \n",
    "### Both TensorFlow and TensorRec can be installed using !pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"tensorflow==1.13.1\"\n",
    "print(n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorrec --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter Prototype\n",
    "### A collaborative filter is an algorithm that learns which users have similar tastes and recommends items to a user based on what similar users have liked. A common way to do this is through matrix factorization. In matrix factorization, we have to learn two matrices (user representations and item representations) that, when multiplied together, approximate the interactions:\n",
    "#### TensorRec will perform matrix factorization by default if it is given only identity matrices as user/item features. These identity matrices are often called “indicator features.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct indicator features for users and items\n",
    "user_indicator_features = sparse.identity(n_users)\n",
    "item_indicator_features = sparse.identity(n_items)\n",
    "\n",
    "# Build a matrix factorization collaborative filter model\n",
    "cf_model = tensorrec.TensorRec(n_components=5)\n",
    "\n",
    "# Fit the collaborative filter model\n",
    "print(\"Training collaborative filter\")\n",
    "cf_model.fit(interactions=sparse_train_ratings,\n",
    "             user_features=user_indicator_features,\n",
    "             item_features=item_indicator_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Graphs\n",
    "### One way we can configure our TensorRec system is by changing the loss graph. The loss graph takes in predictions and interactions and calculates a penalty (loss) that the system will try to decrease as it learns.\n",
    "#### WMRB, which stands for “weighted margin-rank batch,” works by taking a random sample of items the user hasn’t interacted with and comparing their predictions to items the user likes. Over time, this pushes items a user likes to the top of the rankings. We can try using different loss graphs like WARP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Let's try a new loss function: WMRB \n",
    "'''\n",
    "print(\"Training collaborative filter with WMRB loss\")\n",
    "ranking_cf_model = tensorrec.TensorRec(n_components=5,\n",
    "                                       loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "ranking_cf_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                     user_features=user_indicator_features,\n",
    "                     item_features=item_indicator_features,\n",
    "                     n_sampled_items=int(n_items *1))\n",
    "\n",
    "# Check the results of the WMRB MF CF model\n",
    "print(\"WMRB matrix factorization collaborative filter:\")\n",
    "predicted_ranks = ranking_cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                                item_features=item_indicator_features)\n",
    "                                                '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Metadata Features\n",
    "## To continue experimenting, we should try to make use of other data available to us. We will try using User Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To improve the recommendations, lets read in the user demographic data\n",
    "sql = \"\"\"\n",
    "SELECT USERID, FEATURES, STATE\n",
    "FROM `rmf2gcp.RawData.demographics_features` \n",
    "WHERE id_table_dem <= \"\"\" + str(limite)\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_user_metadata = get_data_BQ(sql)\n",
    "print(raw_user_metadata.head(800))\n",
    "print(raw_user_metadata.dtypes)\n",
    "print(raw_user_metadata.columns)\n",
    "raw_user_metadata_header = ['USERID', 'FEATURES', 'STATE']\n",
    "raw_user_metadata_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_user_metadata = raw_user_metadata.values.tolist()\n",
    "raw_user_metadata[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we’ll want to read this data, map the movies to our internal IDs, and keep track of the features for each user. Then we’ll binarize the feature  labels using Scikit’s MultiLabelBinarizer. The binarized output will be our features for our new recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the features IDs to our internal IDs and keep track of the gender and age\n",
    "temp_string = ''\n",
    "temp_list = []\n",
    "count = 1\n",
    "user_id_by_internal_id = {}\n",
    "user_features_by_internal_id = {}\n",
    "for row in raw_user_metadata:\n",
    "    temp_string = ''\n",
    "    temp_list = []\n",
    "    \n",
    "\n",
    "    temp_string = str(row[0])\n",
    "    temp_list = row[1].split(',')\n",
    "    #print(count)\n",
    "    #print(temp_string)\n",
    "    #print(temp_list)\n",
    "    row[0] = idfam1_to_internal_item_ids[int(temp_string)]  # Map to IDs\n",
    "    row[1] = temp_list  # Split up\n",
    "    user_id_by_internal_id[temp_string] = temp_string\n",
    "    user_features_by_internal_id[int(temp_string)] = row[1]\n",
    "    count+=1\n",
    "# Look at an example user metadata row\n",
    "print(\"Raw metadata example:\\n{}\\n{}\".format(raw_user_metadata_header, \n",
    "                                             raw_user_metadata[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ (key, value) for key,value in user_features_by_internal_id.items() ][0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a list of features where the index is the internal user ID and the value is a list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = [user_features_by_internal_id[internal_id]\n",
    "                for internal_id in user_features_by_internal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "29 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the features into binarized labels using scikit's MultiLabelBinarizer\n",
    "user_features = MultiLabelBinarizer().fit_transform(user_feat)\n",
    "n_features = user_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "32 #perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coerce the user features to a sparse matrix, which TensorRec expects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_mat = sparse.coo_matrix(user_features)\n",
    "user_features_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s not as good as the ranking collaborative filter but it’s significantly more effective if we add it to the base collaborative filter.\n",
    "#### There is a major weakness to this system: user feature alone are not very descriptive and are not enough information to make an informed recommendation. If we had more descriptive metadata and item metadata (views, clicks, basket information etc.) we may have more success with this content-based recommender system.\n",
    "#### On the other hand, there is a major strength to this system: by relying on only metadata features, and not using indicator features, we can recommend products which were not present when training the model. Similarly, if we have valuable user metadata we can avoid using user indicator features and make predictions for users who’ve never interacted with a product before. This is called “cold-start” recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid recommender: \n",
    "## Hybrid recommender systems combine two or more recommendation strategies in different ways to benefit from their complementary advantages.\n",
    "### Let’s combine these two: we’ll use indicator features to get the strengths of a collaborative filter, and we’ll also use the content features to take advantage of the metadata. This combination of collaborative filtering and content-based recommendation is the hybrid model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do this by stacking the two sets of features together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try concatenating the user features on to the indicator features for a hybrid recommender system\n",
    "full_user_features = sparse.hstack([user_indicator_features, user_features_mat])\n",
    "full_user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training hybrid recommender\")\n",
    "hybrid_model = tensorrec.TensorRec(\n",
    "    n_components=5\n",
    ")\n",
    "hybrid_model.fit(interactions=sparse_train_ratings,\n",
    "                 user_features=full_user_features,\n",
    "                 item_features=item_indicator_features,\n",
    "                 n_sampled_items=int(n_items * .01))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This performs the best even though we are using trivial features from users. If we have more metadata, we can expect larger impact of the Hybrid recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hybrid recommender:\")\n",
    "predicted_ranks = hybrid_model.predict_rank(user_features=full_user_features,\n",
    "                                            item_features=item_indicator_features)\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Performance metrics: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the model: first prototype\n",
    "#### To do this, we’ll look at a metric called “recall at K.” Recall@K says, for the average user, what percentage of their test items made it in to the top K in the predicted rankings.\n",
    "#### Recall@K is a nice metric for many recommender systems because it emulates the behavior of a recommendation product. Before calculating the recall, we’ll want to decide which interactions should count as a “purchased item.” In this case, choose to use all ratings of at least 1.0 as “liked products” and ignore the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sets of train/test interactions that are only frequency > 1 since these represent the products that have been purchased \n",
    "sparse_train_ratings_1plus = sparse_train_ratings.multiply(sparse_train_ratings >= 1)\n",
    "sparse_test_ratings_1plus = sparse_test_ratings.multiply(sparse_test_ratings >= 1)\n",
    "\n",
    "\n",
    "# This method consumes item ranks for each user and prints out train/test metrics\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Performance metrics: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "\n",
    "# Check the results of the MF CF model\n",
    "print(\"Matrix factorization collaborative filter:\")\n",
    "predicted_ranks = cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                        item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "38 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "39 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "41 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "42 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "43 #perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Recommendation\n",
    "### Now that we have metadata about our user, one thing we can try is to recommend based solely on the user metadata.\n",
    "### To do this, we will configure a TensorRec model to use a pass-through representation graph for item features. For us, this means that the user representations will be the same as the user features that are passed in (just the user information like gender, age etc.) and the item representations will reflect how much the item suits that particular set of user features.\n",
    "#### Ideal case is when we would have item metadata as well: because that would have a greater impact on making the recommendation better- also help solving the cold start problem. There is a major weakness to this system: these features alone are not very descriptive and are not enough information to make an informed recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a content-based model using the user features\n",
    "print(\"Training content-based recommender\")\n",
    "content_model = tensorrec.TensorRec(\n",
    "    n_components=n_features,\n",
    "   user_repr_graph=tensorrec.representation_graphs.FeaturePassThroughRepresentationGraph()\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                  user_features=user_features_mat,\n",
    "                  item_features=item_indicator_features,\n",
    "                  n_sampled_items=int(n_items * .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results of the content-based model\n",
    "print(\"Content-based recommender:\")\n",
    "predicted_ranks = content_model.predict_rank(user_features=user_features_mat,\n",
    "                                             item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "47 #perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "48 # perdido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "49 # perdido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s not as good as the ranking collaborative filter but it’s significantly more effective if we add it to the base collaborative filter.\n",
    "#### There is a major weakness to this system: user feature alone are not very descriptive and are not enough information to make an informed recommendation. If we had more descriptive metadata and item metadata (views, clicks, basket information etc.) we may have more success with this content-based recommender system.\n",
    "#### On the other hand, there is a major strength to this system: by relying on only metadata features, and not using indicator features, we can recommend products which were not present when training the model. Similarly, if we have valuable user metadata we can avoid using user indicator features and make predictions for users who’ve never interacted with a product before. This is called “cold-start” recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making recommendations\n",
    "### We do this by passing the user’s feature vector and all the item features to predict_rank() and examining the resulting rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull user features out of the user features matrix and predict for just that user\n",
    "id_coppel =  12198# el cliente con mas compras en la muestra del %.01 # 18988462 # el cliente con mas compras coppel\n",
    "id_internal = idcte_to_internal_user_ids[id_coppel]\n",
    "print('id_internal {} , para usuario {}'.format(id_internal, id_coppel))\n",
    "u_features = sparse.csr_matrix(user_indicator_features)[id_internal  ] # el menos uno es importante \n",
    "u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "\n",
    "# Get internal IDs of User 432's top 10 recommendations\n",
    "# These are sorted by item ID, not by rank\n",
    "# This may contain items with which User 432 has already interacted\n",
    "k = 10\n",
    "u_top_ten_recs = numpy.where(u_rankings <= k)[0]\n",
    "u_top_ten_recs_foo = u_rankings[0:k]# yo creo que los rankings son mas bien\n",
    "print(\"User x: Item recommendations:\")\n",
    "u_top_ten_recs = [ key for key,value in idfam1_to_internal_item_ids.items() if value in u_top_ten_recs ]\n",
    "u_top_ten_recs.sort()\n",
    "u_top_ten_recs_foo = [ key for key, value in idfam1_to_internal_item_ids.items() if value in u_top_ten_recs_foo]\n",
    "u_top_ten_recs_foo.sort()\n",
    "print(u_top_ten_recs)\n",
    "print(u_top_ten_recs_foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The value of the range over which the recommender should iterate has to be the same as the # of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull user features out of the user features matrix and predict for just all users\n",
    "for user in range(0, n_users, 10000):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    print(\"User\"+str(user)+\": Item recommendations:\")\n",
    "    print(u_top_ten_recs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Internal IDs back to the original IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in range(5):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    print(\"User \"+str(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)])+\": Item recommendations:\")\n",
    "    #print(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)]) \n",
    "    for m in u_top_ten_recs:\n",
    "        print(list(idfam1_to_internal_item_ids.keys())[list(idfam1_to_internal_item_ids.values()).index(m)]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and writing a resulting CSV for recommendations for all users in the input database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "HybridRecommendations=pd.DataFrame([])\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for user in range(n_users):\n",
    "    u_features = sparse.csr_matrix(full_user_features)[user]\n",
    "    u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "    u_top_ten_recs = numpy.where(u_rankings <= 10)[0]\n",
    "    if user %100 ==0 :\n",
    "        print(user)\n",
    "    user_id =str(list(idcte_to_internal_user_ids.keys())[list(idcte_to_internal_user_ids.values()).index(user)])\n",
    "    for m in u_top_ten_recs:\n",
    "        items = (list(idfam1_to_internal_item_ids.keys())[list(idfam1_to_internal_item_ids.values()).index(m)]) \n",
    "        HybridRecommendations=HybridRecommendations.append(pd.DataFrame({'itemId': items,'userId': user_id}, index=[0]), ignore_index=True)\n",
    "t2 = time.time()\n",
    "total = t2-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "idfam1_to_internal_item_ids_REVERSE = {}\n",
    "for key, value in idfam1_to_internal_item_ids.items():\n",
    "    idfam1_to_internal_item_ids_REVERSE[value] = key\n",
    "k = 10\n",
    "\n",
    "from numpy import *\n",
    "u_features = sparse.csr_matrix(full_user_features)\n",
    "u_rankings = hybrid_model.predict_rank(user_features=u_features,\n",
    "                                          item_features=item_indicator_features)\n",
    "    \n",
    "result = [list(flatnonzero(row  <= k)) for row in u_rankings]\n",
    "result = numpy.matrix(result)\n",
    "result = pd.DataFrame(result, columns=[ 'item' + str( i+1) for i in range(k)] )\n",
    "result['userId'] = idcte_to_internal_user_ids.keys()\n",
    "result = pd.melt(result, id_vars=['userId'], value_vars=[ 'item' + str( i+1) for i in range(k)])\n",
    "del result['variable']\n",
    "result = result.rename(columns={\"value\": \"itemId\"})\n",
    "result['itemId'] = result['itemId'].apply( lambda x: idfam1_to_internal_item_ids_REVERSE[x])\n",
    "result\n",
    "table_id = 'Resultados.test_tensorrec_1porciento_17_junio_2020'\n",
    "result.to_gbq(table_id, project_id='rmf2gcp')\n",
    "t3 = time.time()\n",
    "total = t3-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Recommender can also be used to predict similar items given some item IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.predict_similar_items(item_features=item_indicator_features,item_ids=[3,55,90], n_similar=10) #sera util para los usuarios de compra en efectivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
