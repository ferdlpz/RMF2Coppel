{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "#!pip install pyspark\n#!pip install --upgrade google-cloud-bigquery[pandas]\n#!pip install pyspark[sql] #PARSEO RAPIDO DE PANDAS A SPARK RDDSQL"}, {"cell_type": "markdown", "metadata": {}, "source": "### Importing the libraries and starting the Spark Session"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "import pyspark.sql.functions as sql_func\nfrom pyspark.sql.types import *\nfrom pyspark.ml.recommendation import ALS, ALSModel\nfrom pyspark.context import SparkContext \nfrom pyspark.sql import SparkSession\nfrom pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\nfrom pyspark.ml.evaluation import RegressionEvaluator\nimport pandas as pd"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "#!export ARROW_PRE_0_15_IPC_FORMAT=1\n#!echo $ARROW_PRE_0_15_IPC_FORMAT"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "sc = SparkContext.getOrCreate()"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "spark = SparkSession(sc)\nspark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "#from pyspark.context import \nspark = SparkSession(sc)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Add asset from remote connection "}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": "final_stat = None"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\nFROM `rmf2gcp.RawData.Workflow_aggregado`\nWHERE id_table_dem <= 949285\n"}], "source": "# Get data from GCP- BQ\nfrom google.cloud import bigquery\nimport time\nt0 = time.time()\n\nporcentaje = 5\nlimite = int(189857 * porcentaje)\n\ndef get_data_BQ(sql):\n    client = bigquery.Client()\n    df = client.query(sql).to_dataframe()\n    return(df)\nsql =  '''SELECT USERID as ID_CTE, ID_FAM as ID_CLAS1, FREQUENCY as FREQUENCY\nFROM `rmf2gcp.RawData.Workflow_aggregado`\nWHERE id_table_dem <= ''' + str(limite) #310 588 606 ''' # corre en mi local y pesa 56MB %1 del total de la muestra\nprint(sql)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "final_stat = get_data_BQ(sql)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "ID_CTE       int64\nID_CLAS1     int64\nFREQUENCY    int64\ndtype: object\n(18297493, 3)\n"}], "source": "print(final_stat.dtypes)\nprint(final_stat.shape)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/usr/lib/spark/python/pyspark/sql/session.py:714: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n  An error occurred while calling z:org.apache.spark.sql.api.python.PythonSQLUtils.readArrowStreamFromFile.\n: java.lang.IllegalArgumentException\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:334)\n\tat org.apache.arrow.vector.ipc.message.MessageSerializer.readMessage(MessageSerializer.java:543)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$$anon$3.readNextBatch(ArrowConverters.scala:243)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$$anon$3.<init>(ArrowConverters.scala:229)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$.getBatchesFromStream(ArrowConverters.scala:228)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$.$anonfun$readArrowStreamFromFile$2(ArrowConverters.scala:216)\n\tat org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2543)\n\tat org.apache.spark.sql.execution.arrow.ArrowConverters$.readArrowStreamFromFile(ArrowConverters.scala:214)\n\tat org.apache.spark.sql.api.python.PythonSQLUtils$.readArrowStreamFromFile(PythonSQLUtils.scala:46)\n\tat org.apache.spark.sql.api.python.PythonSQLUtils.readArrowStreamFromFile(PythonSQLUtils.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\nAttempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true.\n  warnings.warn(msg)\n"}, {"name": "stdout", "output_type": "stream", "text": "+-------+--------+---------+\n| ID_CTE|ID_CLAS1|FREQUENCY|\n+-------+--------+---------+\n| 179537|  418276|        6|\n| 330344|  102089|        6|\n|3998222|  863047|        9|\n|4484634|  102164|        6|\n|4347906|  314064|        8|\n+-------+--------+---------+\nonly showing top 5 rows\n\n"}], "source": "final_stat = spark.createDataFrame(final_stat)\nfinal_stat.show(5)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pyspark.sql.dataframe.DataFrame'>\n"}], "source": "final_stat.count()\nprint(type(final_stat))"}, {"cell_type": "markdown", "metadata": {}, "source": "### Preparing data for the model"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "ratings = (final_stat\n    .select(\n        'ID_CTE',\n        'ID_CLAS1',\n        'FREQUENCY',\n    )\n).cache()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Spliting the data set to test and train for measuring the performance of the ALS Model"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "(training, test) = ratings.randomSplit([0.8, 0.2])"}, {"cell_type": "markdown", "metadata": {}, "source": "### Build the recommendation model using ALS on the training data\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Root-mean-square error = 1.5660879622147785\n"}], "source": "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\nals = ALS(maxIter=2, regParam=0.01, \n          userCol=\"ID_CTE\", itemCol=\"ID_CLAS1\", ratingCol=\"FREQUENCY\",\n          coldStartStrategy=\"drop\",\n          implicitPrefs=True)\n\nmodel = als.fit(ratings)\n\n# Evaluate the model by computing the RMSE on the test data\npredictions = model.transform(test)\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"FREQUENCY\",\n                                predictionCol=\"prediction\")\n\nrmse = evaluator.evaluate(predictions)\nprint(\"Root-mean-square error = \" + str(rmse))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+--------+---------+------------+\n| ID_CTE|ID_CLAS1|FREQUENCY|  prediction|\n+-------+--------+---------+------------+\n| 182609|  212010|        1| 6.243836E-4|\n|1170487|  212010|        1| 4.522957E-4|\n|2916818|  212010|        1|4.1393048E-4|\n|1784655|  212010|        1| 3.915355E-6|\n| 340914|  212010|        1|1.5606423E-4|\n+-------+--------+---------+------------+\nonly showing top 5 rows\n\n"}], "source": "predictions.show(5)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Parameters of ALS Model in PySpark realization are following:\n\n##### NumBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation.\n##### rank is the number of latent factors in the model.\n##### maxIter is the maximum number of iterations to run.\n##### regParam specifies the regularization parameter in ALS.\n##### implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).\n##### alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0)"}, {"cell_type": "markdown", "metadata": {}, "source": "###  Generate top 10 Item recommendations for each user\n\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "949285\n+------+--------------------+\n|ID_CTE|     recommendations|\n+------+--------------------+\n| 10362|[[380283, 0.11308...|\n| 11033|[[319059, 0.37997...|\n| 11141|[[105068, 0.38442...|\n| 12940|[[380283, 0.81013...|\n| 13832|[[318009, 0.57493...|\n+------+--------------------+\nonly showing top 5 rows\n\n"}], "source": "userRecs = model.recommendForAllUsers(10)\nprint(userRecs.count())\nuserRecs.show(5)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": "[Row(ID_CTE=10362, recommendations=[Row(ID_CLAS1=380283, rating=0.11308000981807709), Row(ID_CLAS1=670015, rating=0.09247514605522156), Row(ID_CLAS1=860049, rating=0.08445228636264801), Row(ID_CLAS1=314156, rating=0.0811886265873909), Row(ID_CLAS1=862009, rating=0.07975541800260544), Row(ID_CLAS1=224009, rating=0.07354674488306046), Row(ID_CLAS1=101028, rating=0.06908357888460159), Row(ID_CLAS1=701305, rating=0.0670555979013443), Row(ID_CLAS1=860048, rating=0.0660824403166771), Row(ID_CLAS1=315131, rating=0.06450476497411728)]),\n Row(ID_CTE=11033, recommendations=[Row(ID_CLAS1=319059, rating=0.3799772560596466), Row(ID_CLAS1=701305, rating=0.3051292896270752), Row(ID_CLAS1=314063, rating=0.27488651871681213), Row(ID_CLAS1=313152, rating=0.2649444341659546), Row(ID_CLAS1=318203, rating=0.2637958228588104), Row(ID_CLAS1=318073, rating=0.24786736071109772), Row(ID_CLAS1=380073, rating=0.24770447611808777), Row(ID_CLAS1=318009, rating=0.23988865315914154), Row(ID_CLAS1=317073, rating=0.22006937861442566), Row(ID_CLAS1=313155, rating=0.2189292013645172)])]"}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": "userRecs.take(2)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|     recommendations|\n+--------------------+\n|[[380283, 0.11308...|\n|[[319059, 0.37997...|\n|[[105068, 0.38442...|\n|[[380283, 0.81013...|\n|[[318009, 0.57493...|\n|[[860048, 0.41832...|\n|[[318009, 0.43979...|\n|[[224009, 0.27071...|\n|[[224009, 0.54601...|\n|[[313152, 1.26762...|\n|[[313152, 0.60337...|\n|[[860048, 0.71588...|\n|[[862009, 0.16757...|\n|[[102016, 0.20113...|\n|[[860048, 0.39464...|\n|[[229032, 0.65287...|\n|[[313152, 0.64600...|\n|[[106055, 0.26870...|\n|[[319059, 0.95158...|\n|[[224009, 0.68381...|\n+--------------------+\nonly showing top 20 rows\n\n"}], "source": "userRecs[['recommendations']].show()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": "1"}, "execution_count": 20, "metadata": {}, "output_type": "execute_result"}], "source": "1"}, {"cell_type": "markdown", "metadata": {}, "source": "### Display the recommendations and get them in the correct format"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+--------------------+\n|ID_CTE|     recommendations|\n+------+--------------------+\n| 10362|[380283, 0.11308001]|\n| 10362|[670015, 0.092475...|\n| 10362|[860049, 0.08445229]|\n| 10362|[314156, 0.08118863]|\n+------+--------------------+\nonly showing top 4 rows\n\n"}], "source": "from pyspark.sql.functions import explode\nuserRecs1=userRecs.withColumn(\"recommendations\", explode(userRecs.recommendations))\nuserRecs1.show(4)"}, {"cell_type": "markdown", "metadata": {}, "source": "####  Breaking down reach recommendation to separate columns"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "userRecs1= userRecs1.select('ID_CTE', 'recommendations.*')       "}, {"cell_type": "markdown", "metadata": {}, "source": "### Display the results"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+--------+-----------+\n|ID_CTE|ID_CLAS1|     rating|\n+------+--------+-----------+\n| 10362|  380283| 0.11308001|\n| 10362|  670015|0.092475146|\n+------+--------+-----------+\nonly showing top 2 rows\n\n"}], "source": "userRecs1.show(2) "}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": "9492850"}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}], "source": "userRecs1.count()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Writing the Output back to the Remote Datasource"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[ID_CTE: int, ID_CLAS1: int, rating: float]"}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": "final_stat = userRecs1.toPandas()\nuserRecs1.unpersist(True)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied: pandas_gbq in /opt/conda/anaconda/lib/python3.7/site-packages (0.13.2)\nRequirement already satisfied: google-auth-oauthlib in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (0.4.1)\nRequirement already satisfied: pydata-google-auth in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (1.1.0)\nRequirement already satisfied: google-cloud-bigquery>=1.11.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (1.25.0)\nRequirement already satisfied: pandas>=0.19.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (1.0.4)\nRequirement already satisfied: setuptools in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (41.4.0)\nRequirement already satisfied: google-auth in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas_gbq) (1.17.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth-oauthlib->pandas_gbq) (1.3.0)\nRequirement already satisfied: six<2.0.0dev,>=1.13.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (1.15.0)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (3.12.2)\nRequirement already satisfied: google-resumable-media<0.6dev,>=0.5.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (0.5.1)\nRequirement already satisfied: google-api-core<2.0dev,>=1.15.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (1.20.0)\nRequirement already satisfied: google-cloud-core<2.0dev,>=1.1.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-cloud-bigquery>=1.11.1->pandas_gbq) (1.3.0)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas>=0.19.0->pandas_gbq) (1.17.2)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas>=0.19.0->pandas_gbq) (2019.3)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from pandas>=0.19.0->pandas_gbq) (2.8.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth->pandas_gbq) (4.1.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth->pandas_gbq) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /opt/conda/anaconda/lib/python3.7/site-packages (from google-auth->pandas_gbq) (4.6)\nRequirement already satisfied: requests>=2.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (2.23.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (3.1.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/anaconda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery>=1.11.1->pandas_gbq) (1.52.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/anaconda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth->pandas_gbq) (0.4.8)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (2019.9.11)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas_gbq) (1.24.2)\n"}], "source": "#!pip install pandas_gbq"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": "'Resultados.test_spark_05porciento_17_junio_2020'"}, "execution_count": 27, "metadata": {}, "output_type": "execute_result"}], "source": "table_id = 'Resultados.test_spark_0'+str(porcentaje)+'porciento_17_junio_2020'\ntable_id"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "1it [01:58, 118.90s/it]"}, {"name": "stdout", "output_type": "stream", "text": "2610.5999677181244\n"}, {"name": "stderr", "output_type": "stream", "text": "\n"}], "source": "final_stat.to_gbq(table_id, project_id='rmf2gcp')\nt3 = time.time()\ntotal = t3-t0\nprint(total)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#!mkdir test/"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#final_stat.to_csv('test_spark_0'+str(porcentaje)+'porciento_17_junio_2020')"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#!gsutil cp test_gcp_cluster_10_junio_2020.csv gs://resultadosrmf2/prueba_gcp_01porciento/test_local_10_junio_2020.csv"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#!zip test_gcp_cluster_10_junio_2020.csv.zip test_gcp_cluster_10_junio_2020.csv"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#!ls"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#!gsutil cp test_gcp_cluster_10_junio_2020.csv.zip gs://resultadosrmf2/prueba_gcp_01porciento/test_local_10_junio_2020.csv.zip"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "##!rm -r test_modelos\n#!mkdir test_modelos_gcp\n#!chmod 777 test_modelos_gcp"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#from pyspark.ml import Pipeline"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#pipeline = Pipeline(stages=[model])"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#model_alsWML = pipeline.fit(ratings)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#model_alsWML.save('/test_modelos_gcp/')"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#!ls -la"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#!gsutil cp test_gcp_cluster_10_junio_2020.csv.zip gs://resultadosrmf2/prueba_gcp_01porciento/test_local_10_junio_2020.csv.zip"}], "metadata": {"environment": {"name": "tf-gpu.1-15.m48", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m48"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}