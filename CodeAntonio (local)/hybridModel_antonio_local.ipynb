{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRec recommender system:\n",
    "## The input data that it uses: user features, item features, and interactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw ratings load :Each row represents a single rating: one user and one item. We’ll be using these ratings(frequency) as our interactions between the user and the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Open and read in the ratings file\n",
    "print('Loading ratings')\n",
    "with open('transaccional_sample.csv', 'r') as ratings_file:\n",
    "    ratings_file_reader = csv.reader(ratings_file)\n",
    "    raw_ratings = list(ratings_file_reader)\n",
    "    raw_ratings_header = raw_ratings.pop(0)\n",
    "\n",
    "len(raw_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# Iterate through the input to map Item and User IDs to new internal IDs\n",
    "# The new internal IDs will be created by the defaultdict on insertion\n",
    "idcte_to_internal_user_ids = collections.defaultdict(lambda: len(idcte_to_internal_user_ids))\n",
    "idfam1_to_internal_item_ids = collections.defaultdict(lambda: len(idfam1_to_internal_item_ids))\n",
    "for row in raw_ratings:\n",
    "    row[0] = idcte_to_internal_user_ids[int(row[0])]\n",
    "    row[1] = idfam1_to_internal_item_ids[int(row[1])]\n",
    "    row[2] = float(row[2])\n",
    "n_users = len(idcte_to_internal_user_ids)\n",
    "n_items = len(idfam1_to_internal_item_ids)\n",
    "print(len(idcte_to_internal_user_ids.keys()))\n",
    "print(n_users)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfam1_to_internal_item_ids\n",
    "idcte_to_internal_user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import numpy \n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the ratings and split them in to train/test sets 80%/20%\n",
    "random.shuffle(raw_ratings)  # Shuffles the list in-place\n",
    "cutoff = int(.8 * len(raw_ratings))\n",
    "train_ratings = raw_ratings[:cutoff]\n",
    "test_ratings = raw_ratings[cutoff:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we reorganize these ratings in to a Scipy sparse matrix. In this matrix, every row represents a user and every column is an item. The [i, j]th value in this matrix is User i’s interaction with Item j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This method converts a list of (user, item, rating) to a sparse matrix\n",
    "def interactions_list_to_sparse_matrix(interactions):\n",
    "    users_column, items_column, ratings_column = zip(*interactions)\n",
    "    return sparse.coo_matrix((ratings_column, (users_column, items_column)),\n",
    "                             shape=(n_users, n_items))\n",
    "\n",
    "\n",
    "# Create sparse matrices of interaction data\n",
    "sparse_train_ratings = interactions_list_to_sparse_matrix(raw_ratings) # creo que aqui ponen toda la data para no perder el encoding\n",
    "sparse_test_ratings = interactions_list_to_sparse_matrix(test_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_train_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall tensorflow -y\n",
    "#!pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorrec --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRec will perform matrix factorization by default if it is given only identity matrices as user/item features. These identity matrices are often called “indicator features.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct indicator features for users and items\n",
    "user_indicator_features = sparse.identity(n_users)\n",
    "item_indicator_features = sparse.identity(n_items)\n",
    "\n",
    "# Build a matrix factorization collaborative filter model\n",
    "cf_model = tensorrec.TensorRec(n_components=5)\n",
    "\n",
    "# Fit the collaborative filter model\n",
    "print(\"Training collaborative filter\")\n",
    "cf_model.fit(interactions=sparse_train_ratings,\n",
    "             user_features=user_indicator_features,\n",
    "             item_features=item_indicator_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sets of train/test interactions that are only frequency > 1 since these represent the products that have been purchased \n",
    "sparse_train_ratings_1plus = sparse_train_ratings.multiply(sparse_train_ratings >= 1)\n",
    "sparse_test_ratings_1plus = sparse_test_ratings.multiply(sparse_test_ratings >= 1)\n",
    "\n",
    "\n",
    "# This method consumes item ranks for each user and prints out recall@10 train/test metrics\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings_1plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Recall at 10: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "\n",
    "# Check the results of the MF CF model\n",
    "print(\"Matrix factorization collaborative filter:\")\n",
    "predicted_ranks = cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                        item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEXT PHASE: TO IMPROVE AND KEEP ADDING DIFFERENT DIMENSIONS TO THE CLASSIC COLLABORATIVE FILTERING MODEL AND SEE IF THERE ARE IMPROVEMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRec will perform matrix factorization by default if it is given only identity matrices as user/item features. These identity matrices are often called “indicator features.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//STILL WORKING ON THIS\n",
    "# Let's try a new loss function: WMRB \n",
    "#print(\"Training collaborative filter with WMRB loss\")\n",
    "#ranking_cf_model = tensorrec.TensorRec(n_components=5,\n",
    "#                                       loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "#ranking_cf_model.fit(interactions=sparse_train_ratings_1plus,\n",
    " #                    user_features=user_indicator_features,\n",
    "  #                   item_features=item_indicator_features,\n",
    "   #                  n_sampled_items=int(n_items *1))\n",
    "\n",
    "# Check the results of the WMRB MF CF model\n",
    "#print(\"WMRB matrix factorization collaborative filter:\")\n",
    "#predicted_ranks = ranking_cf_model.predict_rank(user_features=user_indicator_features,\n",
    " #                                               item_features=item_indicator_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Metadata Features\n",
    "## To continue experimenting, we should try to make use of other data available to us. We will try using User Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# To improve the recommendations, lets read in the user demographic data\n",
    "print('Loading user metadata')\n",
    "with open('transaccional_sample_features_combined.csv', 'r') as users_file:\n",
    "    users_file_reader = csv.reader(users_file)\n",
    "    raw_user_metadata = list(users_file_reader)\n",
    "    raw_user_metadata_header = raw_user_metadata.pop(0)\n",
    "raw_user_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the features IDs to our internal IDs and keep track of the gender and age\n",
    "user_id_by_internal_id = {}\n",
    "user_features_by_internal_id = {}\n",
    "for row in raw_user_metadata:\n",
    "    row[0] = idfam1_to_internal_item_ids[int(row[0])]  # Map to IDs\n",
    "    row[1] = row[1].split(',')  # Split up\n",
    "    user_id_by_internal_id[row[0]] = row[0]\n",
    "    user_features_by_internal_id[row[0]] = row[1]\n",
    "\n",
    "# Look at an example user metadata row\n",
    "print(\"Raw metadata example:\\n{}\\n{}\".format(raw_user_metadata_header, \n",
    "                                             raw_user_metadata[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_by_internal_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of features where the index is the internal user ID and\n",
    "# the value is a list of features\n",
    "user_feat = [user_features_by_internal_id[internal_id]\n",
    "                for internal_id in user_features_by_internal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "29 #perdido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the features into binarized labels using scikit's MultiLabelBinarizer\n",
    "user_features = MultiLabelBinarizer().fit_transform(user_feat)\n",
    "n_features = user_features.shape[1]\n",
    "#print(\"Binarized features example for user {}:\\n{}\".format(user_id_by_internal_id[0], \n",
    " #                                                         user_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features #perdido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coerce the user features to a sparse matrix, which TensorRec expects\n",
    "user_features_mat = sparse.coo_matrix(user_features)\n",
    "user_features_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Recommendation\n",
    "### Now that we have metadata about our user, one thing we can try is to recommend based solely on the user metadata.\n",
    "### //Ideal case is when I would have item metadata: because that would have a greater impact on making the recommendation better- also help solving the cold start problem. There is a major weakness to this system: these features alone are not very descriptive and are not enough information to make an informed recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a content-based model using the user features\n",
    "print(\"Training content-based recommender\")\n",
    "content_model = tensorrec.TensorRec(\n",
    "    n_components=n_features,\n",
    "    user_repr_graph=tensorrec.representation_graphs.FeaturePassThroughRepresentationGraph()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(content_model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                  user_features=user_features_mat,\n",
    "                  item_features=item_indicator_features,\n",
    "                  n_sampled_items=int(n_items * .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results of the content-based model\n",
    "print(\"Content-based recommender:\")\n",
    "predicted_ranks = content_model.predict_rank(user_features=user_features_mat,\n",
    "                                             item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid recommender\n",
    "### Let’s combine these two: we’ll use indicator features to get the strengths of a collaborative filter, and we’ll also use the content features to take advantage of the metadata. This combination of collaborative filtering and content-based recommendation is the hybrid model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do this by stacking the two sets of features together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try concatenating the user features on to the indicator features for a hybrid recommender system\n",
    "full_user_features = sparse.hstack([  user_indicator_features, user_features_mat])\n",
    "full_user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_indicator_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training hybrid recommender\")\n",
    "hybrid_model = tensorrec.TensorRec(\n",
    "    n_components=5\n",
    ")\n",
    "hybrid_model.fit(interactions=sparse_train_ratings_1plus,\n",
    "                 user_features=full_user_features,\n",
    "                 item_features=item_indicator_features,\n",
    "                 n_sampled_items=int(n_items * .01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hybrid recommender:\")\n",
    "predicted_ranks = hybrid_model.predict_rank(user_features=full_user_features,\n",
    "                                            item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull user features out of the user features matrix and predict for just that user\n",
    "u_features = sparse.csr_matrix(user_indicator_features)[2001]\n",
    "u_rankings = hybrid_model.predict_rank(user_features=u432_features,\n",
    "                                          item_features=item_indicator_features)[0]\n",
    "\n",
    "# Get internal IDs of User 432's top 10 recommendations\n",
    "# These are sorted by item ID, not by rank\n",
    "# This may contain items with which User 432 has already interacted\n",
    "u_top_ten_recs = numpy.where(u432_rankings <= 10)[0]\n",
    "print(\"User x: Item recommendations:\")\n",
    "u_top_ten_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in u_top_ten_recs:\n",
    "    print(item_by_internal_id[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
